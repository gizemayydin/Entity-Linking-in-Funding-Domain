{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs\n",
    "Input variables to the first cell.\n",
    "\n",
    "* `PATH_TO_MODEL`: Path to the trained model\n",
    "* `PATH_TO_DATA`: Path to the labelled dataset that should be used to evalaute the model. T\n",
    "    1. Prepare the data\n",
    "        * The dataset should be a list of dictionaries. Each dictionary should correspond to one sample. The keys of the dictionary are \"tokens\", which stores a list of strings corresponding to the tokenized version of the input sentence, and \"tags\", the IOB tag for each token.\n",
    "            ```python\n",
    "            data = [\n",
    "                        {\"tokens\":['token_a','token_b'],\"tags\":['tag_a','tag_b']},\n",
    "                        {\"tokens\":['token_a','token_b','token_c'],\"tags\":['tag_a','tag_b','tag_c']},\n",
    "                        ...\n",
    "                    ]\n",
    "            ```\n",
    "        * IOB tags: `\"O\", \"B_ORG\", \"I_ORG\", \"B_GRT\", \"I_GRT\"`\n",
    "        * Tokenization of the input: Please make sure you tokenize the input with:\n",
    "        ```python\n",
    "        from transformers import PreTrainedTokenizerFast\n",
    "        tokenizer = PreTrainedTokenizerFast.from_pretrained('bert-base-cased')\n",
    "        ```\n",
    "        If a word is split into subwords, make sure to tag it appropriately. Example:\n",
    "            * word: `\"word_xyz\"`, tag: `\"O\"`, tokenized: `\"word\", \"##_\", \"##xyz\"`\n",
    "                * Corresponding tags for the tokenized wordpieces: `\"O\",-100,-100`\n",
    "        Hence, assign the tag to the first WordPiece, and assing the integer -100 to the rest of the wordpieces\n",
    "    2. Pickle the data\n",
    "    ```python\n",
    "with open(path_to_bert_validation_data,'wb') as f:\n",
    "            pickle.dump(data,f)\n",
    "    ```\n",
    "    3. How will the data be unpickled here?\n",
    "    ```python\n",
    "with open(path_to_bert_validation_data,'rb') as f:\n",
    "            data=pickle.load(f)\n",
    "        \n",
    "    * This notebook does not include support for sequences longer than 512, even though they are included in the evaluation of the original research\n",
    "\n",
    "# Outputs\n",
    "Results printed at the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUTS\n",
    "PATH_TO_MODEL = \"bert_sc_ner.pt\"\n",
    "PATH_TO_DATA = \"bert_validation_data.pkl\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############LIBRARIES################\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast\n",
    "import torch\n",
    "from datasets import load_metric\n",
    "from seqeval.scheme import IOB2\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############FUNCTIONS################\n",
    "#From the example GitHub Notebook\n",
    "def compute_metrics(p,id2tag):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [id2tag[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2tag[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    print(\"\\t\\tORG Precision: \",results['_ORG']['precision'])\n",
    "    print(\"\\t\\tORG Recall: \",results['_ORG']['recall'])\n",
    "    print(\"\\t\\tORG F1: \",results['_ORG']['f1'])\n",
    "    print(\"\\t\\tGRT Precision: \",results['_GRT']['precision'])\n",
    "    print(\"\\t\\tGRT Recall: \",results['_GRT']['recall'])\n",
    "    print(\"\\t\\tGRT F1: \",results['_GRT']['f1'])\n",
    "    \n",
    "    \n",
    "#Evaluate the model on the train_monitor set\n",
    "def eval_on_valid(model, train_monitor_loader,id2tag):\n",
    "    #Accumulate the predictions here\n",
    "    val_preds = np.zeros((0,512,5))\n",
    "    #Accumulate the labels here\n",
    "    val_lbls = np.zeros((0,512))\n",
    "    #Accumulate the oss here\n",
    "    val_loss = 0\n",
    "    #Loop over minibatches\n",
    "    for i_val, batch_val in enumerate(train_monitor_loader):\n",
    "        print(i_val,\"/\",len(train_monitor_loader))\n",
    "        #Get the max length in this batch and crop based on that\n",
    "        seq_lens = batch_val['seq_len']\n",
    "        max_len_for_batch = max(seq_lens.cpu().detach().numpy())\n",
    "        #Get inputs and labels for that batch and crop\n",
    "        input_ids_val = torch.tensor(batch_val['input_ids'][:,:max_len_for_batch].detach().numpy()).to(device)\n",
    "        attention_mask_val = torch.tensor(batch_val['attention_mask'][:,:max_len_for_batch].detach().numpy()).to(device)\n",
    "        labels_val = torch.tensor(batch_val['labels'][:,:max_len_for_batch].detach().numpy()).to(device)\n",
    "        #Do a forward pass\n",
    "        outputs_val = model(input_ids_val, attention_mask=attention_mask_val, labels=labels_val)\n",
    "        #First index is the loss. Since the output loss is the mean over minibatch samples,\n",
    "        #we multiply it with batch size. Later, we divide it by the number of samples\n",
    "        val_loss += outputs_val[0].item()\n",
    "        #Save the loss and labels\n",
    "        these_preds = outputs_val[1].cpu().detach().numpy()\n",
    "        these_labels= labels_val.cpu().detach().numpy()\n",
    "        #Pad the predictions again\n",
    "        new_preds = np.ones((len(input_ids_val),512,5)) * -100\n",
    "        new_labels= np.ones((len(input_ids_val),512)) * -100\n",
    "        new_preds[:,:max_len_for_batch,:] = these_preds\n",
    "        new_labels[:,:max_len_for_batch] = these_labels\n",
    "        #Store in array\n",
    "        val_preds = np.concatenate([val_preds,new_preds],axis=0)\n",
    "        val_lbls = np.concatenate([val_lbls,new_labels],axis=0)\n",
    "    print(\"\\tValidation Loss: \",val_loss/len(train_monitor_loader))\n",
    "    p = (val_preds, val_lbls)\n",
    "    print(\"\\tValidation Results: \")\n",
    "    compute_metrics(p,id2tag)\n",
    "    return val_preds\n",
    "\n",
    "\n",
    "#Class for funding bodies dataset\n",
    "class FB_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels,at_mask,seq_lens):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.at_mask = at_mask\n",
    "        self.seq_lens = seq_lens\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = dict()\n",
    "        item['input_ids'] = torch.tensor(self.encodings[idx])\n",
    "        item['attention_mask'] = torch.tensor(self.at_mask[idx])\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        item['seq_len'] =self.seq_lens[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "#Add [CLS] and [SEP] tokens, pad until \"pad_len\" chars.\n",
    "def add_and_pad(lst,pad_len,cls,sep,pad):\n",
    "    new_lst = []\n",
    "    for item in lst:\n",
    "        new_item = [cls] + item + [sep]\n",
    "        while len(new_item) != pad_len:\n",
    "            new_item.append(pad)\n",
    "        new_lst.append(new_item)\n",
    "    return new_lst\n",
    "    \n",
    "def convert_to_fb_dataset(original_input,tokenizer,max_len=512):\n",
    "    tag2id = {'I_GRT':0, 'O':1,'B_GRT':2, 'B_ORG':3, 'I_ORG':4, -100:-100}\n",
    "    texts = [x['tokens'] for x in original_input]\n",
    "    tags = [x['tags'] for x in original_input]\n",
    "    encodings = tokenizer(texts, is_split_into_words=True,add_special_tokens =False)['input_ids']\n",
    "    seq_lens = [len(x)+2 for x in encodings]\n",
    "    encodings = add_and_pad(encodings,max_len,101,102,0)\n",
    "    attention_mask = [[0 if num==0 else 1 for num in lst]  for lst in encodings]\n",
    "    labels = add_and_pad(tags,max_len,-100,-100,-100)\n",
    "    labels = [[tag2id[x] for x in label]  for label in labels]\n",
    "    \n",
    "    return FB_Dataset(encodings, labels,attention_mask,seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############VARIABLES################\n",
    "id2tag = {0: 'I_GRT', 1: 'O', 2: 'B_GRT', 3: 'B_ORG', 4: 'I_ORG'}\n",
    "tag2id = {'I_GRT':0,  'O':1,  'B_GRT':2,  'B_ORG':3, 'I_ORG':4,-100:-100}\n",
    "with open(PATH_TO_DATA,\"rb\") as f:\n",
    "    val_dataset_orig=pickle.load(f)\n",
    "    \n",
    "val_dataset = convert_to_fb_dataset(val_dataset_orig,tokenizer)\n",
    "#Load metric for evaluation\n",
    "metric = load_metric(\"seqeval\")\n",
    "#Load the model and put in evaluation mode\n",
    "model = torch.load(PATH_TO_MODEL)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############RUN THE MODEL################\n",
    "device = torch.device('cuda')\n",
    "\n",
    "#Put model to device\n",
    "model.to(device)\n",
    "\n",
    "#Set batch size\n",
    "batch_size=32\n",
    "\n",
    "#Initialize the valid loader without shuffling\n",
    "valid_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#Get the predictions and preliminary results\n",
    "with torch.no_grad():\n",
    "    val_preds = eval_on_valid(model, valid_loader,id2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############PREPROCESS THE OUTPUT################\n",
    "\n",
    "#Get predicted label index\n",
    "val_preds2 = np.argmax(val_preds,axis=2)\n",
    "#Get the labels\n",
    "valid_labels = val_dataset.labels\n",
    "#Get predicted label and discard -100 tags\n",
    "val_preds_tagged = []\n",
    "for i in range(len(valid_labels)):\n",
    "    lbls = valid_labels[i]\n",
    "    preds = val_preds2[i]\n",
    "    new_preds = []\n",
    "    for j in range(len(lbls)):\n",
    "        lbl = lbls[j]\n",
    "        pred = preds[j]\n",
    "        if lbl != -100:\n",
    "            new_preds.append(id2tag[pred])\n",
    "    val_preds_tagged.append(new_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####GET THE RESULTS########\n",
    "print(classification_report([x['tags'] for x in val_dataset_orig],val_preds_tagged,scheme=IOB2,\n",
    "                           digits=5,mode='default'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
