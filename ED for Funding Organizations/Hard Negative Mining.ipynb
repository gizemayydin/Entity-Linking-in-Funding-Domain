{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs \n",
    "* `embeddings_folder`: Path to the file containing the entity embeddings that will be used.\n",
    "* `input_batch_size`: Batch size for context model inference.\n",
    "* `model_path`: Path to the context model that will be used.\n",
    "* `model_path_m`: Path to the linear layer that will be used.\n",
    "* `device`: Whether GPU or CPU will be used.\n",
    "* `train_fname`: Path to `train.jsonl` or `dev.jsonl`\n",
    "* `path_to_entity_pool`: Path to `entity_pool.pkl`. This is a dictionary where the keys are IDs of entities and the values are Python sets. Each set contains the entity IDs that is assumed to be pointing to the same entity with the key. Hence, each set should at least contain the key. This dictionary aims to solve the issue where there are duplicate entitiy IDs for the same entity in some Knowledge Bases. If you do not have this issue, just create a dictionary where keys are entity IDs and the values are Python sets only containing those entity IDs.\n",
    "* `out_filename`: Filename of the pickle file that will contain the hard negatives. Convention is: \"DATASET_hard_negatives_ROUND.pkl\". For example, after first round for training data, the filename would be \"train_hard_negatives_1.pkl\"\n",
    "\n",
    "# Outputs \n",
    "Hard negatives are written to the file specified by `out_filename`. They are stored in a list that has the same length with the number of instances in the input dataset. Every list contains the hard negative entities from hardest to easiest. if 3 hard negatives are going to be utilized, the first 3 entitites in the list should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import  BertTokenizerFast, BertModel\n",
    "from queue import PriorityQueue\n",
    "import annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_folder = 'entity_embeds_1.pkl'\n",
    "input_batch_size = 256\n",
    "model_path = 'randomneg_ctxt_model.pt'\n",
    "model_path_m = 'randomneg_m.pt'\n",
    "seed = 0\n",
    "device='cuda'\n",
    "train_fname = \"train.jsonl\"\n",
    "path_to_entity_pool = \"entity_pool.pkl\"\n",
    "out_filename = 'train_hard_negatives_1.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_entity_pool,\"rb\") as f:\n",
    "    entity_pool = pickle.load(f)\n",
    "    \n",
    "with open(embeddings_folder,\"rb\") as f:\n",
    "    entity_emebeddings=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENT_START_TAG = \"[unused0]\"\n",
    "ENT_END_TAG = \"[unused1]\"\n",
    "def get_context_representation(\n",
    "    sample,\n",
    "    tokenizer,\n",
    "    max_seq_length,\n",
    "    mention_key=\"mention\",\n",
    "    context_key=\"context\",\n",
    "    ent_start_token=ENT_START_TAG,\n",
    "    ent_end_token=ENT_END_TAG,\n",
    "):\n",
    "    # mention_tokens = [Ms] mention [Me]\n",
    "    mention_tokens = []\n",
    "    if sample[mention_key] and len(sample[mention_key]) > 0:\n",
    "        mention_tokens = tokenizer.tokenize(sample[mention_key])\n",
    "        mention_tokens = [ent_start_token] + mention_tokens + [ent_end_token]\n",
    "\n",
    "    context_left = sample[context_key + \"_left\"]\n",
    "    context_right = sample[context_key + \"_right\"]\n",
    "    context_left = tokenizer.tokenize(context_left)\n",
    "    context_right = tokenizer.tokenize(context_right)\n",
    "\n",
    "    left_quota = (max_seq_length - len(mention_tokens)) // 2 - 1\n",
    "    right_quota = max_seq_length - len(mention_tokens) - left_quota - 2\n",
    "    left_add = len(context_left)\n",
    "    right_add = len(context_right)\n",
    "    if left_add <= left_quota:\n",
    "        if right_add > right_quota:\n",
    "            right_quota += left_quota - left_add\n",
    "    else:\n",
    "        if right_add <= right_quota:\n",
    "            left_quota += right_quota - right_add\n",
    "    \n",
    "    context_tokens = (\n",
    "        context_left[-left_quota:] + mention_tokens + context_right[:right_quota]\n",
    "    )\n",
    "    \n",
    "    # mention_tokens = [CLS] left context [Ms] mention [Me] right context [SEP]\n",
    "    context_tokens = [\"[CLS]\"] + context_tokens + [\"[SEP]\"]\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(context_tokens)\n",
    "    padding = [0] * (max_seq_length - len(input_ids))\n",
    "    input_ids += padding\n",
    "    assert len(input_ids) == max_seq_length\n",
    "\n",
    "    return {\n",
    "        \"tokens\": context_tokens,\n",
    "        \"ids\": input_ids,\n",
    "    }\n",
    "\n",
    "\n",
    "def select_field(data, key1, key2=None):\n",
    "    if key2 is None:\n",
    "        return [example[key1] for example in data]\n",
    "    else:\n",
    "        return [example[key1][key2] for example in data]\n",
    "def process_mention_data_2(samples,tokenizer):\n",
    "    \n",
    "    max_context_length=64\n",
    "    mention_key=\"mention\"\n",
    "    context_key=\"context\"\n",
    "    ent_start_token=\"[unused0]\"\n",
    "    ent_end_token=\"[unused1]\"\n",
    "    \n",
    "    processed_samples = []\n",
    "    all_samples = []\n",
    "    iter_ = samples\n",
    "\n",
    "    for idx, sample in enumerate(iter_):\n",
    "        context_tokens = get_context_representation(sample,tokenizer,max_context_length,mention_key,context_key,ent_start_token,ent_end_token)\n",
    "                        \n",
    "        record = {\"context\": context_tokens}\n",
    "            \n",
    "        processed_samples.append(record)\n",
    "        all_samples.append(sample)\n",
    "        \n",
    "    context_vecs = torch.tensor(\n",
    "        select_field(processed_samples, \"context\", \"ids\"), dtype=torch.long,\n",
    "    )\n",
    "    data = {\n",
    "        \"context_vecs\": context_vecs,\n",
    "        \"sample\":all_samples\n",
    "    }\n",
    "\n",
    "    tensor_data = TensorDataset(context_vecs)\n",
    "    return data, tensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctxt_model = torch.load(model_path).to(device)\n",
    "m = torch.load(model_path_m).to('cpu')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "ctxt_model.eval()\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data \n",
    "train_samples = []\n",
    "with open(train_fname, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        train_samples.append(json.loads(line.strip()))\n",
    "print(len(train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_entities = [x['label_id'] for x in train_samples]\n",
    "\n",
    "train_data, train_tensor_data = process_mention_data_2(train_samples,tokenizer)\n",
    "\n",
    "train_sampler = SequentialSampler(train_tensor_data)\n",
    "train_dataloader = DataLoader(train_tensor_data, sampler=train_sampler, batch_size=input_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctxt_model.eval()\n",
    "print(len(train_dataloader))\n",
    "mention_embeddings = []\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    for step, context_input in enumerate(train_dataloader):\n",
    "        if step%10==0:\n",
    "            print(\"Step: \",step,\" \",time.time()-start)\n",
    "        context_input = context_input[0]\n",
    "        this_batch= context_input.size(0)\n",
    "        ctxt_rep = ctxt_model(context_input.to(device))[0][:,0,:]\n",
    "        for i in range(this_batch):\n",
    "            mention_embeddings.append(ctxt_rep[i].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Param for positive class\n",
    "m_second_param = list(m.parameters())[0][1].detach().numpy()\n",
    "\n",
    "entity_emebeddings_with_m = dict()\n",
    "keys_map = dict()\n",
    "ctr = 0\n",
    "for k,v in entity_emebeddings.items():\n",
    "    entity_emebeddings_with_m[ctr] = np.multiply(m_second_param,v)\n",
    "    keys_map[ctr] = k\n",
    "    ctr+=1\n",
    "    \n",
    "t = annoy.AnnoyIndex(768, 'dot') \n",
    "\n",
    "t.set_seed(0)\n",
    "\n",
    "for k,v in entity_emebeddings_with_m.items():\n",
    "    t.add_item(k, v)\n",
    "t.build(1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hard_negs=30\n",
    "\n",
    "hard_negatives = []\n",
    "start = time.time()\n",
    "#Loop over mentions \n",
    "for i in range(len(mention_embeddings)):\n",
    "    if i%100 == 0:\n",
    "        print(i, \" \",time.time()-start)\n",
    "    #Get the mention embedding\n",
    "    this_ment_embed = mention_embeddings[i]\n",
    "    \n",
    "    #Get score of corr entity for hard neg mining\n",
    "    score_corr_ent = 0.\n",
    "    this_corr_ent = set([None])\n",
    "    if correct_entities[i] is not None:\n",
    "        #Get all correct entities\n",
    "        this_corr_ent = entity_pool[str(int(correct_entities[i]))]\n",
    "        \n",
    "    #Now we get the top num_hard_negs predictions\n",
    "    res = t.get_nns_by_vector(this_ment_embed, num_hard_negs, search_k=len(entity_emebeddings_with_m), include_distances=True)\n",
    "    #Store entities and scores\n",
    "    #Score = -dot\n",
    "    returned_entities = [keys_map[x] for x in res[0]]\n",
    "    scores = [1- 1/(1 + np.exp(x)) for x in res[1]]\n",
    "    merged = list(zip(scores,returned_entities))\n",
    "    #Sort returned instances\n",
    "    merged.sort(key=lambda tup: tup[0],reverse=True) \n",
    "    \n",
    "    #Get hard negatives\n",
    "    this_hard_negs = []\n",
    "    if None in this_corr_ent:\n",
    "        for tup in merged:\n",
    "            this_hard_negs.append(tup[1])\n",
    "            #if tup[0]>=0.5:\n",
    "            #    this_hard_negs.append(tup[1])\n",
    "            #else:\n",
    "            #    break\n",
    "    else:\n",
    "        for tup in merged:\n",
    "            #If this is not one of the corrects, it is a hard negative\n",
    "            if str(tup[1]) not in this_corr_ent:\n",
    "                this_hard_negs.append(tup[1])\n",
    "            #If you find the correct entity stop checking\n",
    "            else:\n",
    "                break\n",
    "    #Set hard negs to None if we cannot find any\n",
    "    if len(this_hard_negs) == 0:\n",
    "        this_hard_negs = []\n",
    "\n",
    "    hard_negatives.append(this_hard_negs)\n",
    "\n",
    "with open(out_filename,'wb') as f:\n",
    "    pickle.dump(hard_negatives,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
