{"cells":[{"cell_type":"code","source":["%pip install transformers==3.5.1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d34a6ce-cc62-482a-bb80-925868389eb6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting transformers==3.5.1\n  Using cached transformers-3.5.1-py3-none-any.whl (1.3 MB)\nCollecting tokenizers==0.9.3\n  Using cached tokenizers-0.9.3-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\nCollecting filelock\n  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\nRequirement already satisfied: packaging in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from transformers==3.5.1) (20.4)\nCollecting sacremoses\n  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from transformers==3.5.1) (1.19.2)\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from transformers==3.5.1) (2020.10.15)\nCollecting sentencepiece==0.1.91\n  Using cached sentencepiece-0.1.91-cp38-cp38-manylinux1_x86_64.whl (1.1 MB)\nRequirement already satisfied: requests in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from transformers==3.5.1) (2.24.0)\nRequirement already satisfied: protobuf in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from transformers==3.5.1) (3.13.0)\nRequirement already satisfied: tqdm&gt;=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from transformers==3.5.1) (4.50.2)\nRequirement already satisfied: six in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from packaging-&gt;transformers==3.5.1) (1.15.0)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from packaging-&gt;transformers==3.5.1) (2.4.7)\nRequirement already satisfied: joblib in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (0.17.0)\nRequirement already satisfied: click in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (7.1.2)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (2.10)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (2020.12.5)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (1.25.11)\nRequirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (3.0.4)\nRequirement already satisfied: setuptools in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from protobuf-&gt;transformers==3.5.1) (50.3.1.post20201107)\nInstalling collected packages: tokenizers, filelock, sacremoses, sentencepiece, transformers\nSuccessfully installed filelock-3.0.12 sacremoses-0.0.45 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting transformers==3.5.1\n  Using cached transformers-3.5.1-py3-none-any.whl (1.3 MB)\nCollecting tokenizers==0.9.3\n  Using cached tokenizers-0.9.3-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\nCollecting filelock\n  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\nRequirement already satisfied: packaging in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from transformers==3.5.1) (20.4)\nCollecting sacremoses\n  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from transformers==3.5.1) (1.19.2)\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from transformers==3.5.1) (2020.10.15)\nCollecting sentencepiece==0.1.91\n  Using cached sentencepiece-0.1.91-cp38-cp38-manylinux1_x86_64.whl (1.1 MB)\nRequirement already satisfied: requests in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from transformers==3.5.1) (2.24.0)\nRequirement already satisfied: protobuf in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from transformers==3.5.1) (3.13.0)\nRequirement already satisfied: tqdm&gt;=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from transformers==3.5.1) (4.50.2)\nRequirement already satisfied: six in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from packaging-&gt;transformers==3.5.1) (1.15.0)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from packaging-&gt;transformers==3.5.1) (2.4.7)\nRequirement already satisfied: joblib in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (0.17.0)\nRequirement already satisfied: click in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (7.1.2)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (2.10)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (2020.12.5)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (1.25.11)\nRequirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (3.0.4)\nRequirement already satisfied: setuptools in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from protobuf-&gt;transformers==3.5.1) (50.3.1.post20201107)\nInstalling collected packages: tokenizers, filelock, sacremoses, sentencepiece, transformers\nSuccessfully installed filelock-3.0.12 sacremoses-0.0.45 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%pip install datasets==1.4.1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9586a932-5aaa-4a36-8952-6fddff0801d0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting datasets==1.4.1\n  Downloading datasets-1.4.1-py3-none-any.whl (186 kB)\nRequirement already satisfied: dill in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from datasets==1.4.1) (0.3.2)\nRequirement already satisfied: numpy&gt;=1.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from datasets==1.4.1) (1.19.2)\nCollecting tqdm&lt;4.50.0,&gt;=4.27\n  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\nRequirement already satisfied: pyarrow&gt;=0.17.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from datasets==1.4.1) (1.0.1)\nCollecting xxhash\n  Downloading xxhash-2.0.2-cp38-cp38-manylinux2010_x86_64.whl (243 kB)\nCollecting multiprocess\n  Downloading multiprocess-0.70.11.1-py38-none-any.whl (126 kB)\nRequirement already satisfied: pandas in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from datasets==1.4.1) (1.1.3)\nCollecting huggingface-hub==0.0.2\n  Downloading huggingface_hub-0.0.2-py3-none-any.whl (24 kB)\nCollecting fsspec\n  Downloading fsspec-2021.4.0-py3-none-any.whl (108 kB)\nRequirement already satisfied: requests&gt;=2.19.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from datasets==1.4.1) (2.24.0)\nRequirement already satisfied: pytz&gt;=2017.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from pandas-&gt;datasets==1.4.1) (2020.5)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from pandas-&gt;datasets==1.4.1) (2.8.1)\nRequirement already satisfied: filelock in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from huggingface-hub==0.0.2-&gt;datasets==1.4.1) (3.0.12)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests&gt;=2.19.0-&gt;datasets==1.4.1) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests&gt;=2.19.0-&gt;datasets==1.4.1) (2.10)\nRequirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests&gt;=2.19.0-&gt;datasets==1.4.1) (3.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests&gt;=2.19.0-&gt;datasets==1.4.1) (2020.12.5)\nRequirement already satisfied: six&gt;=1.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;datasets==1.4.1) (1.15.0)\nInstalling collected packages: tqdm, xxhash, multiprocess, huggingface-hub, fsspec, datasets\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.50.2\n    Uninstalling tqdm-4.50.2:\n      Successfully uninstalled tqdm-4.50.2\nERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n\nmultiprocess 0.70.11.1 requires dill&gt;=0.3.3, but you&#39;ll have dill 0.3.2 which is incompatible.\nSuccessfully installed datasets-1.4.1 fsspec-2021.4.0 huggingface-hub-0.0.2 multiprocess-0.70.11.1 tqdm-4.49.0 xxhash-2.0.2\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting datasets==1.4.1\n  Downloading datasets-1.4.1-py3-none-any.whl (186 kB)\nRequirement already satisfied: dill in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from datasets==1.4.1) (0.3.2)\nRequirement already satisfied: numpy&gt;=1.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from datasets==1.4.1) (1.19.2)\nCollecting tqdm&lt;4.50.0,&gt;=4.27\n  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\nRequirement already satisfied: pyarrow&gt;=0.17.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from datasets==1.4.1) (1.0.1)\nCollecting xxhash\n  Downloading xxhash-2.0.2-cp38-cp38-manylinux2010_x86_64.whl (243 kB)\nCollecting multiprocess\n  Downloading multiprocess-0.70.11.1-py38-none-any.whl (126 kB)\nRequirement already satisfied: pandas in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from datasets==1.4.1) (1.1.3)\nCollecting huggingface-hub==0.0.2\n  Downloading huggingface_hub-0.0.2-py3-none-any.whl (24 kB)\nCollecting fsspec\n  Downloading fsspec-2021.4.0-py3-none-any.whl (108 kB)\nRequirement already satisfied: requests&gt;=2.19.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from datasets==1.4.1) (2.24.0)\nRequirement already satisfied: pytz&gt;=2017.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from pandas-&gt;datasets==1.4.1) (2020.5)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from pandas-&gt;datasets==1.4.1) (2.8.1)\nRequirement already satisfied: filelock in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from huggingface-hub==0.0.2-&gt;datasets==1.4.1) (3.0.12)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests&gt;=2.19.0-&gt;datasets==1.4.1) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests&gt;=2.19.0-&gt;datasets==1.4.1) (2.10)\nRequirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests&gt;=2.19.0-&gt;datasets==1.4.1) (3.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from requests&gt;=2.19.0-&gt;datasets==1.4.1) (2020.12.5)\nRequirement already satisfied: six&gt;=1.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;datasets==1.4.1) (1.15.0)\nInstalling collected packages: tqdm, xxhash, multiprocess, huggingface-hub, fsspec, datasets\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.50.2\n    Uninstalling tqdm-4.50.2:\n      Successfully uninstalled tqdm-4.50.2\nERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n\nmultiprocess 0.70.11.1 requires dill&gt;=0.3.3, but you&#39;ll have dill 0.3.2 which is incompatible.\nSuccessfully installed datasets-1.4.1 fsspec-2021.4.0 huggingface-hub-0.0.2 multiprocess-0.70.11.1 tqdm-4.49.0 xxhash-2.0.2\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%pip install seqeval==1.2.2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1c41b5fc-5a86-46e6-96b0-74810c2f1722"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting seqeval==1.2.2\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\nRequirement already satisfied: numpy&gt;=1.14.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from seqeval==1.2.2) (1.19.2)\nRequirement already satisfied: scikit-learn&gt;=0.21.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from seqeval==1.2.2) (0.23.2)\nRequirement already satisfied: scipy&gt;=0.19.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from scikit-learn&gt;=0.21.3-&gt;seqeval==1.2.2) (1.5.2)\nRequirement already satisfied: joblib&gt;=0.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from scikit-learn&gt;=0.21.3-&gt;seqeval==1.2.2) (0.17.0)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from scikit-learn&gt;=0.21.3-&gt;seqeval==1.2.2) (2.1.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py): started\n  Building wheel for seqeval (setup.py): finished with status &#39;done&#39;\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16170 sha256=c21d022926f5eaeeaca510c70425779dafa1adab3851c8eac8fbd8f93fc1f48f\n  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting seqeval==1.2.2\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\nRequirement already satisfied: numpy&gt;=1.14.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from seqeval==1.2.2) (1.19.2)\nRequirement already satisfied: scikit-learn&gt;=0.21.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from seqeval==1.2.2) (0.23.2)\nRequirement already satisfied: scipy&gt;=0.19.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from scikit-learn&gt;=0.21.3-&gt;seqeval==1.2.2) (1.5.2)\nRequirement already satisfied: joblib&gt;=0.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from scikit-learn&gt;=0.21.3-&gt;seqeval==1.2.2) (0.17.0)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages (from scikit-learn&gt;=0.21.3-&gt;seqeval==1.2.2) (2.1.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py): started\n  Building wheel for seqeval (setup.py): finished with status &#39;done&#39;\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16170 sha256=c21d022926f5eaeeaca510c70425779dafa1adab3851c8eac8fbd8f93fc1f48f\n  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import time\nimport numpy as np\nimport random\nimport pickle\nimport torch\nfrom torch.utils.data import DataLoader\nfrom transformers import get_linear_schedule_with_warmup\nfrom datasets import load_metric\nfrom transformers import BertForTokenClassification\nseed_num=0\nnp.random.seed(seed_num)\nrandom.seed(seed_num)\ntorch.manual_seed(seed_num)\ntorch.cuda.manual_seed(seed_num)\ntorch.cuda.manual_seed_all(seed_num)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7df28981-291a-407f-b26f-ddab3a9ba7ef"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#From the example GitHub Notebook\ndef compute_metrics(p,id2tag):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [id2tag[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [id2tag[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    print(\"\\t\\tORG Precision: \",results['_ORG']['precision'])\n    print(\"\\t\\tORG Recall: \",results['_ORG']['recall'])\n    print(\"\\t\\tORG F1: \",results['_ORG']['f1'])\n    print(\"\\t\\tGRT Precision: \",results['_GRT']['precision'])\n    print(\"\\t\\tGRT Recall: \",results['_GRT']['recall'])\n    print(\"\\t\\tGRT F1: \",results['_GRT']['f1'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4350317b-025b-4204-9d39-b638b6a3afab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Evaluate the model on the train_monitor set\ndef eval_on_valid(model, train_monitor_loader,id2tag):\n    #Accumulate the predictions here\n    val_preds = np.zeros((0,512,5))\n    #Accumulate the labels here\n    val_lbls = np.zeros((0,512))\n    #Accumulate the oss here\n    val_loss = 0\n    #Loop over minibatches\n    for i_val, batch_val in enumerate(train_monitor_loader):\n        #Get the max length in this batch and crop based on that\n        seq_lens = batch_val['seq_len']\n        max_len_for_batch = max(seq_lens.cpu().detach().numpy())\n        #Get inputs and labels for that batch and crop\n        input_ids_val = torch.tensor(batch_val['input_ids'][:,:max_len_for_batch].detach().numpy()).to(device)\n        attention_mask_val = torch.tensor(batch_val['attention_mask'][:,:max_len_for_batch].detach().numpy()).to(device)\n        labels_val = torch.tensor(batch_val['labels'][:,:max_len_for_batch].detach().numpy()).to(device)\n        #Do a forward pass\n        outputs_val = model(input_ids_val, attention_mask=attention_mask_val, labels=labels_val)\n        #First index is the loss. Since the output loss is the mean over minibatch samples,\n        #we multiply it with batch size. Later, we divide it by the number of samples\n        val_loss += outputs_val[0].item()\n        #Save the loss and labels\n        these_preds = outputs_val[1].cpu().detach().numpy()\n        these_labels= labels_val.cpu().detach().numpy()\n        #Pad the predictions again\n        new_preds = np.ones((len(input_ids_val),512,5)) * -100\n        new_labels= np.ones((len(input_ids_val),512)) * -100\n        new_preds[:,:max_len_for_batch,:] = these_preds\n        new_labels[:,:max_len_for_batch] = these_labels\n        #Store in array\n        val_preds = np.concatenate([val_preds,new_preds],axis=0)\n        val_lbls = np.concatenate([val_lbls,new_labels],axis=0)\n    print(\"\\tValidation Loss: \",val_loss/len(train_monitor_loader))\n    p = (val_preds, val_lbls)\n    print(\"\\tValidation Results: \")\n    compute_metrics(p,id2tag)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a9870fc-ca06-452e-883a-a7645d548f24"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Class for funding bodies dataset\nclass FB_Dataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels,at_mask,seq_lens):\n        self.encodings = encodings\n        self.labels = labels\n        self.at_mask = at_mask\n        self.seq_lens = seq_lens\n\n    def __getitem__(self, idx):\n        item = dict()\n        item['input_ids'] = torch.tensor(self.encodings[idx])\n        item['attention_mask'] = torch.tensor(self.at_mask[idx])\n        item['labels'] = torch.tensor(self.labels[idx])\n        item['seq_len'] =self.seq_lens[idx]\n        return item\n\n    def __len__(self):\n        return len(self.labels)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85b6eee8-9f2d-4455-830a-a04622d0762b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["model = BertForTokenClassification.from_pretrained('/dbfs/mnt/els-nlp-experts1/data/Gizem/bert-base-cased-tapt3/checkpoint-1000', num_labels=5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f51740db-ebd4-4d07-be29-a7d4cf2cf6b9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Some weights of the model checkpoint at /dbfs/mnt/els-nlp-experts1/data/Gizem/bert-base-cased-tapt3/checkpoint-1000 were not used when initializing BertForTokenClassification: [&#39;cls.predictions.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.predictions.decoder.bias&#39;]\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at /dbfs/mnt/els-nlp-experts1/data/Gizem/bert-base-cased-tapt3/checkpoint-1000 and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;]\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Some weights of the model checkpoint at /dbfs/mnt/els-nlp-experts1/data/Gizem/bert-base-cased-tapt3/checkpoint-1000 were not used when initializing BertForTokenClassification: [&#39;cls.predictions.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.predictions.decoder.bias&#39;]\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at /dbfs/mnt/els-nlp-experts1/data/Gizem/bert-base-cased-tapt3/checkpoint-1000 and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;]\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["with open(\"/dbfs/mnt/els-nlp-experts1/data/Gizem/bert_datasets.pkl\",'rb') as f:\n    train_dataset=pickle.load(f)\n    train_monitor_dataset=pickle.load(f)\nid2tag= {0: 'I_GRT', 1: 'O', 2: 'B_GRT', 3: 'B_ORG', 4: 'I_ORG'}\nmetric = load_metric(\"seqeval\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"205bbb72-c24d-4023-80ef-49d8655d8017"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\rDownloading:   0%|          | 0.00/1.96k [00:00&lt;?, ?B/s]\rDownloading: 4.95kB [00:00, 3.70MB/s]                   \n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\rDownloading:   0%|          | 0.00/1.96k [00:00&lt;?, ?B/s]\rDownloading: 4.95kB [00:00, 3.70MB/s]                   \n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import gc"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28c9fa1f-ba25-489f-8422-a71dd2c6412f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Pick the device\ndevice = torch.device('cuda')\n\n#Put model to device\nmodel.to(device)\n\n#Put model to training mode\nmodel.train()\n\n#Define training batch size\nbatch_size=8#increase this\nnum_epochs = 2\n\n#Get training sample generator\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntrain_monitor_loader = DataLoader(train_monitor_dataset, batch_size=batch_size, shuffle=True)\n\n#Initialize optimizer\noptim = torch.optim.AdamW(model.parameters(), lr=2e-5) \n\n#Determine how many steps each epoch will take\nprint(\"Steps per epoch: \" ,len(train_loader))\n\nscheduler = get_linear_schedule_with_warmup(optim, \n                                            num_warmup_steps = 50, \n                                            num_training_steps = len(train_loader)*num_epochs)\n\nminibatch_losses = []\n#Every x step, print training loss\nevery_x_step=500\n\n#Loop over epochs\nfor epoch in range(num_epochs):\n    print(\"Epoch: \",epoch)\n    #Loop over minibatches\n    #Accumulate training statistics\n    train_loss = 0\n    train_preds = np.zeros((0,512,5))\n    train_lbls = np.zeros((0,512))\n    for i, batch in enumerate(train_loader):\n        gc.collect()\n        start = time.time()\n        #reset gradients\n        optim.zero_grad()\n        #Get the max length in this batch and crop based on that\n        seq_lens = batch['seq_len']\n        max_len_for_batch = max(seq_lens.cpu().detach().numpy())\n        #get inputs\n        input_ids = torch.tensor(batch['input_ids'][:,:max_len_for_batch].detach().numpy()).to(device)\n        attention_mask = torch.tensor(batch['attention_mask'][:,:max_len_for_batch].detach().numpy()).to(device)\n        labels = torch.tensor(batch['labels'][:,:max_len_for_batch].detach().numpy()).to(device)\n        #When we call a classification model with the labels argument, the first returned element is the Cross Entropy loss between the predictions and the passed labels. \n        #Calculate loss\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        #attention_mask.detach()\n        del attention_mask\n        #loss is reduced by mean (so it roughly corresponds to loss of one sample)\n        #https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n        #https://huggingface.co/transformers/_modules/transformers/models/bert/modeling_bert.html#BertForTokenClassification.forward\n        loss = outputs[0]\n        #Print loss\n        train_loss+=loss.item()\n        #Second index is the predictions, store them\n        these_preds = outputs[1].cpu().detach().numpy()\n        these_labels= labels.cpu().detach().numpy()\n        del outputs\n        #labels.detach()\n        del labels\n        #Pad the predictions again\n        new_preds = np.ones((len(input_ids),512,5)) * -100\n        new_labels= np.ones((len(input_ids),512)) * -100\n        #input_ids.detach()\n        del input_ids\n        new_preds[:,:max_len_for_batch,:] = these_preds\n        new_labels[:,:max_len_for_batch] = these_labels\n        #Save the labels\n        train_lbls = np.concatenate([train_lbls,new_labels],axis=0)\n        train_preds = np.concatenate([train_preds,new_preds],axis=0)\n        #backpropagation\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        #update the parameters\n        optim.step()\n        scheduler.step()\n        end = time.time()\n        minibatch_losses.append(loss.item())\n        torch.cuda.empty_cache()\n        #Every x step, print validation scores\n        if (i+1)%every_x_step==0:          \n            #Print training loss for this minibatch\n            print(\"\\tStep \",i+1,\"/\",len(train_loader))\n            print(\"\\t\\tBatch padding: \",max_len_for_batch)\n            print(\"\\t\\tMinibatch training loss: \",loss.item())\n            print(\"\\t\\tTime for this minibatch: \",end-start)\n            #Check val loss\n            model.eval()\n            with torch.no_grad():\n                #Evaluate the current model on the validation set\n                eval_on_valid(model, train_monitor_loader,id2tag)\n            model.train()\n            #Save Model\n            #with open(\"/dbfs/mnt/els-nlp-experts1/data/Gizem/bert_epoch_\"+str(epoch)+\"_step_\"+str(i)+'.pt','wb') as f:\n            #    torch.save(model, f)\n       \n    print(\"\\tApproximate Training loss for this epoch: \",train_loss/len(train_loader))\n    print(\"\\tApproximate Training results: \")\n    compute_metrics((train_preds, train_lbls),id2tag)\n    #Check val loss\n    model.eval()\n    with torch.no_grad():\n        #Evaluate the current model on the validation set\n        eval_on_valid(model, train_monitor_loader,id2tag)\n    model.train()\n    with open(\"/dbfs/mnt/els-nlp-experts1/data/Gizem/bert_epoch_\"+str(epoch)+'.pt','wb') as f:\n        torch.save(model, f)\n\n\nmodel.eval()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"863bdadb-eb6c-48a2-9fcd-63a3eb694ed8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Steps per epoch:  3277\nEpoch:  0\n\tStep  500 / 3277\n\t\tBatch padding:  97\n\t\tMinibatch training loss:  0.2548289895057678\n\t\tTime for this minibatch:  0.36392879486083984\n\tValidation Loss:  0.17924442102252705\n\tValidation Results: \n/local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ORG seems not to be NE tag.\n  warnings.warn(&#39;{} seems not to be NE tag.&#39;.format(chunk))\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ORG seems not to be NE tag.\n  warnings.warn(&#39;{} seems not to be NE tag.&#39;.format(chunk))\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_GRT seems not to be NE tag.\n  warnings.warn(&#39;{} seems not to be NE tag.&#39;.format(chunk))\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_GRT seems not to be NE tag.\n  warnings.warn(&#39;{} seems not to be NE tag.&#39;.format(chunk))\n\t\tORG Precision:  0.7100319035802907\n\t\tORG Recall:  0.864106988783434\n\t\tORG F1:  0.7795290912628916\n\t\tGRT Precision:  0.9374266718811107\n\t\tGRT Recall:  0.9645875251509054\n\t\tGRT F1:  0.9508131693772313\n\tStep  1000 / 3277\n\t\tBatch padding:  229\n\t\tMinibatch training loss:  0.1730986386537552\n\t\tTime for this minibatch:  0.7196481227874756\n\tValidation Loss:  0.15653683646850608\n\tValidation Results: \n\t\tORG Precision:  0.7585482330468004\n\t\tORG Recall:  0.8565573770491803\n\t\tORG F1:  0.8045790700030392\n\t\tGRT Precision:  0.948828125\n\t\tGRT Recall:  0.9774647887323944\n\t\tGRT F1:  0.9629335976214074\n\tStep  1500 / 3277\n\t\tBatch padding:  123\n\t\tMinibatch training loss:  0.11925635486841202\n\t\tTime for this minibatch:  0.5155174732208252\n\tValidation Loss:  0.15428947628778547\n\tValidation Results: \n\t\tORG Precision:  0.7647788342290203\n\t\tORG Recall:  0.7981018119068162\n\t\tORG F1:  0.7810850749419463\n\t\tGRT Precision:  0.947265625\n\t\tGRT Recall:  0.9758551307847082\n\t\tGRT F1:  0.9613478691774034\n\tStep  2000 / 3277\n\t\tBatch padding:  103\n\t\tMinibatch training loss:  0.0955638736486435\n\t\tTime for this minibatch:  0.5272684097290039\n\tValidation Loss:  0.14694718129795753\n\tValidation Results: \n\t\tORG Precision:  0.7774970851146522\n\t\tORG Recall:  0.8630284728213977\n\t\tORG F1:  0.8180331220609282\n\t\tGRT Precision:  0.9520628683693517\n\t\tGRT Recall:  0.9750503018108652\n\t\tGRT F1:  0.9634194831013917\n\tStep  2500 / 3277\n\t\tBatch padding:  135\n\t\tMinibatch training loss:  0.08346577733755112\n\t\tTime for this minibatch:  0.6436529159545898\n\tValidation Loss:  0.14362650701313343\n\tValidation Results: \n\t\tORG Precision:  0.7709007808036564\n\t\tORG Recall:  0.8731665228645384\n\t\tORG F1:  0.818853039344594\n\t\tGRT Precision:  0.9481481481481482\n\t\tGRT Recall:  0.9786720321931589\n\t\tGRT F1:  0.9631683168316832\n\tStep  3000 / 3277\n\t\tBatch padding:  185\n\t\tMinibatch training loss:  0.08737931400537491\n\t\tTime for this minibatch:  0.7917890548706055\n\tValidation Loss:  0.14277442070466975\n\tValidation Results: \n\t\tORG Precision:  0.7681241718720424\n\t\tORG Recall:  0.8753235547886109\n\t\tORG F1:  0.8182276439157172\n\t\tGRT Precision:  0.9523064894448788\n\t\tGRT Recall:  0.9802816901408451\n\t\tGRT F1:  0.9660916121356334\n\tApproximate Training loss for this epoch:  0.17083655761172303\n\tApproximate Training results: \n\t\tORG Precision:  0.7243545945366612\n\t\tORG Recall:  0.8025768911055694\n\t\tORG F1:  0.7614621402567405\n\t\tGRT Precision:  0.9061550793115086\n\t\tGRT Recall:  0.9431588653727936\n\t\tGRT F1:  0.9242867593269934\n\tValidation Loss:  0.14091017405485357\n\tValidation Results: \n\t\tORG Precision:  0.7836406433895645\n\t\tORG Recall:  0.8617342536669542\n\t\tORG F1:  0.8208341894390795\n\t\tGRT Precision:  0.9518213866039953\n\t\tGRT Recall:  0.9778672032193159\n\t\tGRT F1:  0.964668519253672\nEpoch:  1\n\tStep  500 / 3277\n\t\tBatch padding:  83\n\t\tMinibatch training loss:  0.2810361385345459\n\t\tTime for this minibatch:  0.32914257049560547\n\tValidation Loss:  0.13984670200059476\n\tValidation Results: \n\t\tORG Precision:  0.7929942608351475\n\t\tORG Recall:  0.8643226919758412\n\t\tORG F1:  0.8271235421612139\n\t\tGRT Precision:  0.9582841401023219\n\t\tGRT Recall:  0.9798792756539235\n\t\tGRT F1:  0.9689614007162755\n\tStep  1000 / 3277\n\t\tBatch padding:  299\n\t\tMinibatch training loss:  0.09179402887821198\n\t\tTime for this minibatch:  0.9059569835662842\n\tValidation Loss:  0.14005496304737908\n\tValidation Results: \n\t\tORG Precision:  0.7805394990366089\n\t\tORG Recall:  0.8738136324417601\n\t\tORG F1:  0.8245471198860167\n\t\tGRT Precision:  0.9530332681017613\n\t\tGRT Recall:  0.9798792756539235\n\t\tGRT F1:  0.9662698412698413\n\tStep  1500 / 3277\n\t\tBatch padding:  64\n\t\tMinibatch training loss:  0.09718318283557892\n\t\tTime for this minibatch:  0.3656926155090332\n\tValidation Loss:  0.14880089905181546\n\tValidation Results: \n\t\tORG Precision:  0.7829099307159353\n\t\tORG Recall:  0.8774805867126834\n\t\tORG F1:  0.8275020341741254\n\t\tGRT Precision:  0.9532048761305545\n\t\tGRT Recall:  0.9754527162977867\n\t\tGRT F1:  0.9642004773269689\n\tStep  2000 / 3277\n\t\tBatch padding:  59\n\t\tMinibatch training loss:  0.08955737203359604\n\t\tTime for this minibatch:  0.4336729049682617\n\tValidation Loss:  0.14371549564505146\n\tValidation Results: \n\t\tORG Precision:  0.7909836065573771\n\t\tORG Recall:  0.8742450388265747\n\t\tORG F1:  0.8305327868852459\n\t\tGRT Precision:  0.9556688897606904\n\t\tGRT Recall:  0.9802816901408451\n\t\tGRT F1:  0.967818831942789\n\tStep  2500 / 3277\n\t\tBatch padding:  140\n\t\tMinibatch training loss:  0.09031196683645248\n\t\tTime for this minibatch:  0.6536831855773926\n\tValidation Loss:  0.14171047977234688\n\tValidation Results: \n\t\tORG Precision:  0.7915768854064642\n\t\tORG Recall:  0.8716566005176877\n\t\tORG F1:  0.8296889436402832\n\t\tGRT Precision:  0.9598425196850394\n\t\tGRT Recall:  0.9810865191146881\n\t\tGRT F1:  0.9703482587064677\n\tStep  3000 / 3277\n\t\tBatch padding:  142\n\t\tMinibatch training loss:  0.041591376066207886\n\t\tTime for this minibatch:  0.6876840591430664\n\tValidation Loss:  0.15003607782643813\n\tValidation Results: \n\t\tORG Precision:  0.7989302694136292\n\t\tORG Recall:  0.8699309749784296\n\t\tORG F1:  0.8329202808756712\n\t\tGRT Precision:  0.9578740157480315\n\t\tGRT Recall:  0.9790744466800805\n\t\tGRT F1:  0.968358208955224\n\tApproximate Training loss for this epoch:  0.11339905355567596\n\tApproximate Training results: \n\t\tORG Precision:  0.8007335132516781\n\t\tORG Recall:  0.8588202113763211\n\t\tORG F1:  0.8287603045343532\n\t\tGRT Precision:  0.9504417567335736\n\t\tGRT Recall:  0.9730613857908141\n\t\tGRT F1:  0.9616185723584293\n\tValidation Loss:  0.13809233914026592\n\tValidation Results: \n\t\tORG Precision:  0.7959143586721665\n\t\tORG Recall:  0.8740293356341674\n\t\tORG F1:  0.8331448545286315\n\t\tGRT Precision:  0.9590389917290272\n\t\tGRT Recall:  0.9798792756539235\n\t\tGRT F1:  0.9693471337579619\nOut[8]: BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=5, bias=True)\n)</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Steps per epoch:  3277\nEpoch:  0\n\tStep  500 / 3277\n\t\tBatch padding:  97\n\t\tMinibatch training loss:  0.2548289895057678\n\t\tTime for this minibatch:  0.36392879486083984\n\tValidation Loss:  0.17924442102252705\n\tValidation Results: \n/local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_ORG seems not to be NE tag.\n  warnings.warn(&#39;{} seems not to be NE tag.&#39;.format(chunk))\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_ORG seems not to be NE tag.\n  warnings.warn(&#39;{} seems not to be NE tag.&#39;.format(chunk))\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_GRT seems not to be NE tag.\n  warnings.warn(&#39;{} seems not to be NE tag.&#39;.format(chunk))\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-3654d7f9-af83-403d-bdcc-0abc23c247b3/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_GRT seems not to be NE tag.\n  warnings.warn(&#39;{} seems not to be NE tag.&#39;.format(chunk))\n\t\tORG Precision:  0.7100319035802907\n\t\tORG Recall:  0.864106988783434\n\t\tORG F1:  0.7795290912628916\n\t\tGRT Precision:  0.9374266718811107\n\t\tGRT Recall:  0.9645875251509054\n\t\tGRT F1:  0.9508131693772313\n\tStep  1000 / 3277\n\t\tBatch padding:  229\n\t\tMinibatch training loss:  0.1730986386537552\n\t\tTime for this minibatch:  0.7196481227874756\n\tValidation Loss:  0.15653683646850608\n\tValidation Results: \n\t\tORG Precision:  0.7585482330468004\n\t\tORG Recall:  0.8565573770491803\n\t\tORG F1:  0.8045790700030392\n\t\tGRT Precision:  0.948828125\n\t\tGRT Recall:  0.9774647887323944\n\t\tGRT F1:  0.9629335976214074\n\tStep  1500 / 3277\n\t\tBatch padding:  123\n\t\tMinibatch training loss:  0.11925635486841202\n\t\tTime for this minibatch:  0.5155174732208252\n\tValidation Loss:  0.15428947628778547\n\tValidation Results: \n\t\tORG Precision:  0.7647788342290203\n\t\tORG Recall:  0.7981018119068162\n\t\tORG F1:  0.7810850749419463\n\t\tGRT Precision:  0.947265625\n\t\tGRT Recall:  0.9758551307847082\n\t\tGRT F1:  0.9613478691774034\n\tStep  2000 / 3277\n\t\tBatch padding:  103\n\t\tMinibatch training loss:  0.0955638736486435\n\t\tTime for this minibatch:  0.5272684097290039\n\tValidation Loss:  0.14694718129795753\n\tValidation Results: \n\t\tORG Precision:  0.7774970851146522\n\t\tORG Recall:  0.8630284728213977\n\t\tORG F1:  0.8180331220609282\n\t\tGRT Precision:  0.9520628683693517\n\t\tGRT Recall:  0.9750503018108652\n\t\tGRT F1:  0.9634194831013917\n\tStep  2500 / 3277\n\t\tBatch padding:  135\n\t\tMinibatch training loss:  0.08346577733755112\n\t\tTime for this minibatch:  0.6436529159545898\n\tValidation Loss:  0.14362650701313343\n\tValidation Results: \n\t\tORG Precision:  0.7709007808036564\n\t\tORG Recall:  0.8731665228645384\n\t\tORG F1:  0.818853039344594\n\t\tGRT Precision:  0.9481481481481482\n\t\tGRT Recall:  0.9786720321931589\n\t\tGRT F1:  0.9631683168316832\n\tStep  3000 / 3277\n\t\tBatch padding:  185\n\t\tMinibatch training loss:  0.08737931400537491\n\t\tTime for this minibatch:  0.7917890548706055\n\tValidation Loss:  0.14277442070466975\n\tValidation Results: \n\t\tORG Precision:  0.7681241718720424\n\t\tORG Recall:  0.8753235547886109\n\t\tORG F1:  0.8182276439157172\n\t\tGRT Precision:  0.9523064894448788\n\t\tGRT Recall:  0.9802816901408451\n\t\tGRT F1:  0.9660916121356334\n\tApproximate Training loss for this epoch:  0.17083655761172303\n\tApproximate Training results: \n\t\tORG Precision:  0.7243545945366612\n\t\tORG Recall:  0.8025768911055694\n\t\tORG F1:  0.7614621402567405\n\t\tGRT Precision:  0.9061550793115086\n\t\tGRT Recall:  0.9431588653727936\n\t\tGRT F1:  0.9242867593269934\n\tValidation Loss:  0.14091017405485357\n\tValidation Results: \n\t\tORG Precision:  0.7836406433895645\n\t\tORG Recall:  0.8617342536669542\n\t\tORG F1:  0.8208341894390795\n\t\tGRT Precision:  0.9518213866039953\n\t\tGRT Recall:  0.9778672032193159\n\t\tGRT F1:  0.964668519253672\nEpoch:  1\n\tStep  500 / 3277\n\t\tBatch padding:  83\n\t\tMinibatch training loss:  0.2810361385345459\n\t\tTime for this minibatch:  0.32914257049560547\n\tValidation Loss:  0.13984670200059476\n\tValidation Results: \n\t\tORG Precision:  0.7929942608351475\n\t\tORG Recall:  0.8643226919758412\n\t\tORG F1:  0.8271235421612139\n\t\tGRT Precision:  0.9582841401023219\n\t\tGRT Recall:  0.9798792756539235\n\t\tGRT F1:  0.9689614007162755\n\tStep  1000 / 3277\n\t\tBatch padding:  299\n\t\tMinibatch training loss:  0.09179402887821198\n\t\tTime for this minibatch:  0.9059569835662842\n\tValidation Loss:  0.14005496304737908\n\tValidation Results: \n\t\tORG Precision:  0.7805394990366089\n\t\tORG Recall:  0.8738136324417601\n\t\tORG F1:  0.8245471198860167\n\t\tGRT Precision:  0.9530332681017613\n\t\tGRT Recall:  0.9798792756539235\n\t\tGRT F1:  0.9662698412698413\n\tStep  1500 / 3277\n\t\tBatch padding:  64\n\t\tMinibatch training loss:  0.09718318283557892\n\t\tTime for this minibatch:  0.3656926155090332\n\tValidation Loss:  0.14880089905181546\n\tValidation Results: \n\t\tORG Precision:  0.7829099307159353\n\t\tORG Recall:  0.8774805867126834\n\t\tORG F1:  0.8275020341741254\n\t\tGRT Precision:  0.9532048761305545\n\t\tGRT Recall:  0.9754527162977867\n\t\tGRT F1:  0.9642004773269689\n\tStep  2000 / 3277\n\t\tBatch padding:  59\n\t\tMinibatch training loss:  0.08955737203359604\n\t\tTime for this minibatch:  0.4336729049682617\n\tValidation Loss:  0.14371549564505146\n\tValidation Results: \n\t\tORG Precision:  0.7909836065573771\n\t\tORG Recall:  0.8742450388265747\n\t\tORG F1:  0.8305327868852459\n\t\tGRT Precision:  0.9556688897606904\n\t\tGRT Recall:  0.9802816901408451\n\t\tGRT F1:  0.967818831942789\n\tStep  2500 / 3277\n\t\tBatch padding:  140\n\t\tMinibatch training loss:  0.09031196683645248\n\t\tTime for this minibatch:  0.6536831855773926\n\tValidation Loss:  0.14171047977234688\n\tValidation Results: \n\t\tORG Precision:  0.7915768854064642\n\t\tORG Recall:  0.8716566005176877\n\t\tORG F1:  0.8296889436402832\n\t\tGRT Precision:  0.9598425196850394\n\t\tGRT Recall:  0.9810865191146881\n\t\tGRT F1:  0.9703482587064677\n\tStep  3000 / 3277\n\t\tBatch padding:  142\n\t\tMinibatch training loss:  0.041591376066207886\n\t\tTime for this minibatch:  0.6876840591430664\n\tValidation Loss:  0.15003607782643813\n\tValidation Results: \n\t\tORG Precision:  0.7989302694136292\n\t\tORG Recall:  0.8699309749784296\n\t\tORG F1:  0.8329202808756712\n\t\tGRT Precision:  0.9578740157480315\n\t\tGRT Recall:  0.9790744466800805\n\t\tGRT F1:  0.968358208955224\n\tApproximate Training loss for this epoch:  0.11339905355567596\n\tApproximate Training results: \n\t\tORG Precision:  0.8007335132516781\n\t\tORG Recall:  0.8588202113763211\n\t\tORG F1:  0.8287603045343532\n\t\tGRT Precision:  0.9504417567335736\n\t\tGRT Recall:  0.9730613857908141\n\t\tGRT F1:  0.9616185723584293\n\tValidation Loss:  0.13809233914026592\n\tValidation Results: \n\t\tORG Precision:  0.7959143586721665\n\t\tORG Recall:  0.8740293356341674\n\t\tORG F1:  0.8331448545286315\n\t\tGRT Precision:  0.9590389917290272\n\t\tGRT Recall:  0.9798792756539235\n\t\tGRT F1:  0.9693471337579619\nOut[8]: BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=5, bias=True)\n)</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c54ea8b1-f243-40d4-ac3a-94572bcf1349"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Train_BERT_NER_PretrainedBERT_3","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3246686}},"nbformat":4,"nbformat_minor":0}
