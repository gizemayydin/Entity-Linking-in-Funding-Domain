Based on the bi-encoder model described in [1] and the hard negative mining described in [2]

Data preprocessing codes from this repository: https://github.com/facebookresearch/BLINK/tree/master/blink

[1]  Ledell Wu, Fabio Petroni, Martin Josifoski, Sebastian Riedel, and Luke Zettlemoyer. Scalable zero-shot entity linking with dense entity retrieval.  InProceedings  of  the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6397–6407, Online, November 2020. Association for Computational Linguistics.

[2]  Daniel Gillick, Sayali Kulkarni, Larry Lansing, Alessandro Presta, Jason Baldridge, Eugene  Ie,  and  Diego  Garcia-Olano.   Learning  dense  representations  for  entity retrieval. InProceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL), pages 528–537, Hong Kong, China, November 2019. Association for Computational Linguistics.
