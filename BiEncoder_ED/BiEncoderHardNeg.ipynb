{"cells":[{"cell_type":"code","source":["%pip install transformers==3.5.1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3deaf16c-e86d-4da6-b57d-602d78823eeb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting transformers==3.5.1\n  Using cached transformers-3.5.1-py3-none-any.whl (1.3 MB)\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from transformers==3.5.1) (2020.10.15)\nCollecting sacremoses\n  Using cached sacremoses-0.0.45-py3-none-any.whl (895 kB)\nCollecting tokenizers==0.9.3\n  Using cached tokenizers-0.9.3-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\nRequirement already satisfied: packaging in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from transformers==3.5.1) (20.4)\nCollecting sentencepiece==0.1.91\n  Using cached sentencepiece-0.1.91-cp38-cp38-manylinux1_x86_64.whl (1.1 MB)\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from transformers==3.5.1) (1.19.2)\nRequirement already satisfied: requests in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from transformers==3.5.1) (2.24.0)\nCollecting filelock\n  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\nRequirement already satisfied: tqdm&gt;=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from transformers==3.5.1) (4.50.2)\nRequirement already satisfied: protobuf in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from transformers==3.5.1) (3.13.0)\nRequirement already satisfied: joblib in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (0.17.0)\nRequirement already satisfied: six in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (1.15.0)\nRequirement already satisfied: click in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (7.1.2)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from packaging-&gt;transformers==3.5.1) (2.4.7)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (1.25.11)\nRequirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (3.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (2020.12.5)\nRequirement already satisfied: setuptools in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from protobuf-&gt;transformers==3.5.1) (50.3.1.post20201107)\nInstalling collected packages: sacremoses, tokenizers, sentencepiece, filelock, transformers\nSuccessfully installed filelock-3.0.12 sacremoses-0.0.45 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting transformers==3.5.1\n  Using cached transformers-3.5.1-py3-none-any.whl (1.3 MB)\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from transformers==3.5.1) (2020.10.15)\nCollecting sacremoses\n  Using cached sacremoses-0.0.45-py3-none-any.whl (895 kB)\nCollecting tokenizers==0.9.3\n  Using cached tokenizers-0.9.3-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\nRequirement already satisfied: packaging in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from transformers==3.5.1) (20.4)\nCollecting sentencepiece==0.1.91\n  Using cached sentencepiece-0.1.91-cp38-cp38-manylinux1_x86_64.whl (1.1 MB)\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from transformers==3.5.1) (1.19.2)\nRequirement already satisfied: requests in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from transformers==3.5.1) (2.24.0)\nCollecting filelock\n  Using cached filelock-3.0.12-py3-none-any.whl (7.6 kB)\nRequirement already satisfied: tqdm&gt;=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from transformers==3.5.1) (4.50.2)\nRequirement already satisfied: protobuf in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from transformers==3.5.1) (3.13.0)\nRequirement already satisfied: joblib in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (0.17.0)\nRequirement already satisfied: six in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (1.15.0)\nRequirement already satisfied: click in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (7.1.2)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from packaging-&gt;transformers==3.5.1) (2.4.7)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (2.10)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (1.25.11)\nRequirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (3.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (2020.12.5)\nRequirement already satisfied: setuptools in /local_disk0/.ephemeral_nfs/envs/pythonEnv-54648c00-ba4c-4df9-9ace-ee12926afa97/lib/python3.8/site-packages (from protobuf-&gt;transformers==3.5.1) (50.3.1.post20201107)\nInstalling collected packages: sacremoses, tokenizers, sentencepiece, filelock, transformers\nSuccessfully installed filelock-3.0.12 sacremoses-0.0.45 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import random\nimport torch\nimport time\nimport numpy as np\nimport pickle\nimport json\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\nfrom transformers import get_linear_schedule_with_warmup,BertTokenizerFast, BertModel"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1fcc29e0-0ed5-435a-a214-29b3156529f1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["INP_PATH = \"/dbfs/mnt/els-nlp-experts1/data/Gizem/\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"59074b5d-b6fd-423c-b0dc-3eee5fa50edd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["##FROM THE BLINK REPO##\nENT_START_TAG = \"[unused0]\"\nENT_END_TAG = \"[unused1]\"\n\ndef select_field(data, key1, key2=None):\n    if key2 is None:\n        return [example[key1] for example in data]\n    else:\n        return [example[key1][key2] for example in data]\n\ndef get_context_representation(\n    sample,\n    tokenizer,\n    max_seq_length,\n    mention_key=\"mention\",\n    context_key=\"context\",\n    ent_start_token=ENT_START_TAG,\n    ent_end_token=ENT_END_TAG,\n):\n    # mention_tokens = [Ms] mention [Me]\n    mention_tokens = []\n    if sample[mention_key] and len(sample[mention_key]) > 0:\n        mention_tokens = tokenizer.tokenize(sample[mention_key])\n        mention_tokens = [ent_start_token] + mention_tokens + [ent_end_token]\n\n    context_left = sample[context_key + \"_left\"]\n    context_right = sample[context_key + \"_right\"]\n    context_left = tokenizer.tokenize(context_left)\n    context_right = tokenizer.tokenize(context_right)\n\n    left_quota = (max_seq_length - len(mention_tokens)) // 2 - 1\n    right_quota = max_seq_length - len(mention_tokens) - left_quota - 2\n    left_add = len(context_left)\n    right_add = len(context_right)\n    if left_add <= left_quota:\n        if right_add > right_quota:\n            right_quota += left_quota - left_add\n    else:\n        if right_add <= right_quota:\n            left_quota += right_quota - right_add\n    \n    context_tokens = (\n        context_left[-left_quota:] + mention_tokens + context_right[:right_quota]\n    )\n    \n    # mention_tokens = [CLS] left context [Ms] mention [Me] right context [SEP]\n    context_tokens = [\"[CLS]\"] + context_tokens + [\"[SEP]\"]\n    input_ids = tokenizer.convert_tokens_to_ids(context_tokens)\n    padding = [0] * (max_seq_length - len(input_ids))\n    input_ids += padding\n    assert len(input_ids) == max_seq_length\n\n    return {\n        \"tokens\": context_tokens,\n        \"ids\": input_ids,\n    }\n\n\ndef get_candidate_representation(label_idx):\n\n    cand_tokens = entity_dict[str(label_idx)]['tokens']\n    input_ids = entity_dict[str(label_idx)]['ids']\n    \n    return {\n        \"tokens\": cand_tokens,\n        \"ids\": input_ids,\n    }\n  \ndef to_bert_input(token_idx,dev_name):\n    \"\"\" token_idx is a 2D tensor int.\n        return token_idx, segment_idx and mask\n    \"\"\"\n    segment_idx = None\n    mask = token_idx != 0\n    if dev_name =='cuda':\n        segment_idx = torch.cuda.LongTensor(token_idx * 0)\n        mask = torch.cuda.LongTensor(mask.long())\n    else:\n        segment_idx = torch.LongTensor(token_idx * 0)\n        mask = torch.LongTensor(mask.long())    \n    return token_idx, segment_idx, mask"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd135806-4ac0-408e-b858-8d0c95790ab1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def process_mention_data(\n    samples,\n    tokenizer,\n    max_context_length,\n    max_cand_length,\n    mention_key=\"mention\",\n    context_key=\"context\",\n    ent_start_token=ENT_START_TAG,\n    ent_end_token=ENT_END_TAG\n):\n    processed_samples = []\n    iter_ = samples\n    all_samples = []\n\n    for idx, sample in enumerate(iter_):\n        context_tokens = get_context_representation(\n            sample,\n            tokenizer,\n            max_context_length,\n            mention_key,\n            context_key,\n            ent_start_token,\n            ent_end_token,\n        )\n        \n        if sample[\"label_id\"] is None:\n          #NIL mention\n          pass\n        else:\n          label_idx = int(sample[\"label_id\"])\n          label_tokens = get_candidate_representation(label_idx)\n          \n          record = {\n              \"context\": context_tokens,\n              \"label\": label_tokens,\n              \"label_idx\": 1,\n              \"sample\":sample\n          }\n          processed_samples.append(record)\n          all_samples.append(sample)\n        \n        for label_idx in sample[\"negative_cands\"]:\n            label_tokens = get_candidate_representation(label_idx)\n            record = {\n                \"context\": context_tokens,\n                \"label\": label_tokens,\n                \"label_idx\": 0,\n                \"sample\":sample\n            }\n            processed_samples.append(record)\n            all_samples.append(sample)\n        \n    context_vecs = torch.tensor(\n        select_field(processed_samples, \"context\", \"ids\"), dtype=torch.long,\n    )\n    cand_vecs = torch.tensor(\n        select_field(processed_samples, \"label\", \"ids\"), dtype=torch.long,\n    )\n    label_idx = torch.tensor(\n        select_field(processed_samples, \"label_idx\"), dtype=torch.long,\n    )\n    data = {\n        \"context_vecs\": context_vecs,\n        \"cand_vecs\": cand_vecs,\n        \"label_idx\": label_idx,\n        \"sample\":all_samples\n    }\n\n    tensor_data = TensorDataset(context_vecs, cand_vecs, label_idx)\n    return data, tensor_data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99415d2c-1e8d-4867-8ff2-659b99428c09"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["seed = 0\ndevice = 'cuda'\nbase_bert_model_ctxt = INP_PATH+\"ctxt_model_epoch_1.pt\"\nbase_bert_model_cand = INP_PATH+\"cand_model_epoch_1.pt\"\nbase_m = INP_PATH+\"m_epoch_1.pt\"\ntrain_fname = INP_PATH+\"biencoder_train.jsonl\"\nmonitor_fname = INP_PATH+\"biencoder_monitor.jsonl\"\nhard_neg_cands_train_path = INP_PATH+\"hard_negatives_training_round_1.pkl\"\nhard_neg_cands_valid_path =  INP_PATH+\"hard_negatives_monitor_round_1.pkl\"\nmax_context_length= 64\ntrain_batch_size = 16\nnum_train_epochs=3\neval_batch_size=256\ngrad_acc_steps=4\nnum_neg_cands=10\ngrad_norm = 1.0\n#class_weights = [0.5,0.5]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7f299cf-28b4-40fc-9ea4-d25b35b30414"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["max_cand_length = 256\n#keys are string\nwith open(INP_PATH+'entities_256.pkl','rb') as f:\n    entity_dict=pickle.load(f)\nwith open(hard_neg_cands_train_path,'rb') as f:\n    hard_neg_cands_train=pickle.load(f)\nwith open(hard_neg_cands_valid_path,'rb') as f:\n    hard_neg_cands_valid=pickle.load(f)\n    \nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7210949-33bc-4492-9a74-65abf8b095ba"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[6]: &lt;torch._C.Generator at 0x7f20d011df10&gt;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[6]: &lt;torch._C.Generator at 0x7f20d011df10&gt;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["ctxt_model = torch.load(base_bert_model_ctxt).to(device)\ncand_model = torch.load(base_bert_model_cand).to(device)\nm = torch.load(base_m).to(device)\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d61f7cd0-4299-4ed4-ba36-7bf12393cea8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Load train data \ntrain_samples = []\nwith open(train_fname, mode=\"r\", encoding=\"utf-8\") as file:\n    for line in file:\n        train_samples.append(json.loads(line.strip()))\nprint(len(train_samples))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"929a9bde-f2db-47e1-9cee-30ea1f225512"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">67145\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">67145\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["for i in range(len(train_samples)):\n    if i%1000==0:\n      print(i)\n    \n    neg_samples = None\n    hard_neg_cands = hard_neg_cands_train[i]\n    \n    #If there are no hard_neg_cands\n    #Sample randomly\n    #Cannot be NIL\n    if hard_neg_cands is None:\n      e_ids = list(entity_dict.keys())\n      e_ids.remove(train_samples[i]['label_id'])\n      neg_samples = np.random.choice(e_ids,num_neg_cands//2,replace=False)\n      \n    #If there are hard_neg_cands\n    else:\n      #Take the last num_neg_cands/2\n      neg_samples = [str(x[1]) for x in hard_neg_cands[-(num_neg_cands//2):]]\n      remaining_slots = num_neg_cands - len(neg_samples)\n      \n      #Remove the selected entity IDs so we do not sample them randomly\n      e_ids = list(entity_dict.keys())\n      for e_id in neg_samples:\n          e_ids.remove(e_id)\n      \n      #Not NIL mention\n      if train_samples[i]['label_id'] is not None:\n        #Remove the correct entity ID so we do not sample it randomly\n        e_ids.remove(train_samples[i]['label_id'])\n      neg_samples = neg_samples + list(np.random.choice(e_ids,remaining_slots,replace=False))\n   \n    neg_samples = [int(x) for x in neg_samples]\n    train_samples[i]['negative_cands'] = neg_samples"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3796412e-2b7b-48fe-86fb-d7a255bf3423"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n11000\n12000\n13000\n14000\n15000\n16000\n17000\n18000\n19000\n20000\n21000\n22000\n23000\n24000\n25000\n26000\n27000\n28000\n29000\n30000\n31000\n32000\n33000\n34000\n35000\n36000\n37000\n38000\n39000\n40000\n41000\n42000\n43000\n44000\n45000\n46000\n47000\n48000\n49000\n50000\n51000\n52000\n53000\n54000\n55000\n56000\n57000\n58000\n59000\n60000\n61000\n62000\n63000\n64000\n65000\n66000\n67000\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n11000\n12000\n13000\n14000\n15000\n16000\n17000\n18000\n19000\n20000\n21000\n22000\n23000\n24000\n25000\n26000\n27000\n28000\n29000\n30000\n31000\n32000\n33000\n34000\n35000\n36000\n37000\n38000\n39000\n40000\n41000\n42000\n43000\n44000\n45000\n46000\n47000\n48000\n49000\n50000\n51000\n52000\n53000\n54000\n55000\n56000\n57000\n58000\n59000\n60000\n61000\n62000\n63000\n64000\n65000\n66000\n67000\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["train_data, train_tensor_data = process_mention_data(\n    train_samples,\n    tokenizer,\n    max_context_length,\n    max_cand_length\n)\n\ntrain_sampler = RandomSampler(train_tensor_data)\ntrain_dataloader = DataLoader(train_tensor_data, sampler=train_sampler, batch_size=train_batch_size)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"694ac014-0a17-4549-a41a-2984df8aed23"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Load eval data\nvalid_samples = []\nwith open(monitor_fname, mode=\"r\", encoding=\"utf-8\") as file:\n    for line in file:\n        valid_samples.append(json.loads(line.strip()))\nprint(len(valid_samples))\n\nfor i in range(len(valid_samples)):\n    if i%1000==0:\n      print(i)\n    \n    neg_samples = None\n    hard_neg_cands = hard_neg_cands_valid[i]\n    \n    #If there are no hard_neg_cands\n    #Sample randomly\n    #Cannot be NIL\n    if hard_neg_cands is None:\n      e_ids = list(entity_dict.keys())\n      e_ids.remove(valid_samples[i]['label_id'])\n      neg_samples = np.random.choice(e_ids,num_neg_cands//2,replace=False)\n      \n    #If there are hard_neg_cands\n    else:\n      #Take the last num_neg_cands/2\n      neg_samples = [str(x[1]) for x in hard_neg_cands[-(num_neg_cands//2):]]\n      remaining_slots = num_neg_cands - len(neg_samples)\n      \n      #Remove the selected entity IDs so we do not sample them randomly\n      e_ids = list(entity_dict.keys())\n      for e_id in neg_samples:\n          e_ids.remove(e_id)\n      \n      #Not NIL mention\n      if valid_samples[i]['label_id'] is not None:\n        #Remove the correct entity ID so we do not sample it randomly\n        e_ids.remove(valid_samples[i]['label_id'])\n      neg_samples = neg_samples + list(np.random.choice(e_ids,remaining_slots,replace=False))\n   \n    neg_samples = [int(x) for x in neg_samples]\n    valid_samples[i]['negative_cands'] = neg_samples\n\nvalid_data, valid_tensor_data = process_mention_data(\n    valid_samples,\n    tokenizer,\n    max_context_length,\n    max_cand_length\n)\nvalid_sampler = SequentialSampler(valid_tensor_data)\nvalid_dataloader = DataLoader(valid_tensor_data, sampler=valid_sampler, batch_size=eval_batch_size)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e25c748d-4546-4a67-a839-2593c8a3dc84"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">4635\n0\n1000\n2000\n3000\n4000\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">4635\n0\n1000\n2000\n3000\n4000\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["optim_cand = torch.optim.AdamW(cand_model.parameters(), lr=2e-5) \nscheduler_cand = get_linear_schedule_with_warmup(optim_cand, \n                                                 num_warmup_steps = 0, \n                                                 num_training_steps = len(train_dataloader) // grad_acc_steps * num_train_epochs)\noptim_ctxt = torch.optim.AdamW(ctxt_model.parameters(), lr=2e-5) \nscheduler_ctxt = get_linear_schedule_with_warmup(optim_ctxt, \n                                                 num_warmup_steps = 0, \n                                                 num_training_steps = len(train_dataloader) // grad_acc_steps * num_train_epochs)\noptim_m = torch.optim.AdamW(m.parameters(), lr=2e-5) \nscheduler_m = get_linear_schedule_with_warmup(optim_m, \n                                                 num_warmup_steps = 0, \n                                                 num_training_steps = len(train_dataloader) // grad_acc_steps * num_train_epochs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8f00d6d-40d4-46ec-83a0-b10a11c56adb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["ctxt_model.eval()\ncand_model.eval()\nm.eval()\nall_loss=0\nprint(\"Number of steps: \",len(valid_dataloader))\nwith torch.no_grad():\n    num_correct = 0\n    num_all = 0\n    for step, batch in enumerate(valid_dataloader):\n\n        context_input, candidate_input, e_ids  = batch\n        longest_cand = torch.max(torch.argmin(candidate_input,dim=1))\n        candidate_input = candidate_input[:,:longest_cand]\n        \n        if step%10==0:\n            print(\"Step:\",step,\" longest cand \",longest_cand)\n            \n        context_token_idx, context_segment_idx, context_mask = to_bert_input(context_input.to(device),device)\n        candidate_token_idx, candidate_segment_idx, candidate_mask = to_bert_input(candidate_input.to(device),device)\n        \n        context_rep = ctxt_model(context_token_idx, context_segment_idx, context_mask)[0][:,0,:]\n        cand_rep = cand_model(candidate_token_idx, candidate_segment_idx, candidate_mask)[0][:,0,:]\n        \n        scores = context_rep.mul(cand_rep)\n        scores = m(scores)\n        \n        loss = torch.nn.functional.cross_entropy(scores, e_ids.to(device))#,weight=torch.tensor(class_weights).to(device))\n        all_loss+=loss\n        outputs = np.argmax(scores.cpu().detach(), axis=1)\n        outputs = np.sum(outputs.numpy() == e_ids.numpy())\n        num_correct += outputs\n        num_all += context_rep.size(0)\nall_loss/=len(valid_dataloader)\nprint(\"Val_Loss: \",all_loss)\nprint(\"Val_Acc: \",num_correct/num_all)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e328ca16-7aa3-4f50-bc5d-035c80429190"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Number of steps:  142\nStep: 0  longest cand  tensor(255)\nStep: 10  longest cand  tensor(133)\nStep: 20  longest cand  tensor(244)\nStep: 30  longest cand  tensor(235)\nStep: 40  longest cand  tensor(252)\nStep: 50  longest cand  tensor(255)\nStep: 60  longest cand  tensor(255)\nStep: 70  longest cand  tensor(255)\nStep: 80  longest cand  tensor(255)\nStep: 90  longest cand  tensor(255)\nStep: 100  longest cand  tensor(133)\nStep: 110  longest cand  tensor(255)\nStep: 120  longest cand  tensor(99)\nStep: 130  longest cand  tensor(255)\nStep: 140  longest cand  tensor(133)\nVal_Loss:  tensor(1.3823, device=&#39;cuda:0&#39;)\nVal_Acc:  0.8095316713444499\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Number of steps:  142\nStep: 0  longest cand  tensor(255)\nStep: 10  longest cand  tensor(133)\nStep: 20  longest cand  tensor(244)\nStep: 30  longest cand  tensor(235)\nStep: 40  longest cand  tensor(252)\nStep: 50  longest cand  tensor(255)\nStep: 60  longest cand  tensor(255)\nStep: 70  longest cand  tensor(255)\nStep: 80  longest cand  tensor(255)\nStep: 90  longest cand  tensor(255)\nStep: 100  longest cand  tensor(133)\nStep: 110  longest cand  tensor(255)\nStep: 120  longest cand  tensor(99)\nStep: 130  longest cand  tensor(255)\nStep: 140  longest cand  tensor(133)\nVal_Loss:  tensor(1.3823, device=&#39;cuda:0&#39;)\nVal_Acc:  0.8095316713444499\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["ctxt_model.train()\ncand_model.train()\nm.train()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28c5cb69-9d8e-4fe5-98d7-660abeccc443"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[13]: Linear(in_features=768, out_features=2, bias=False)</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: Linear(in_features=768, out_features=2, bias=False)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["print('Number of steps per epoch: ',len(train_dataloader))\nprint('Number of steps with accumulation: ',len(train_dataloader)//grad_acc_steps)\n\n#Reset Gradients\noptim_cand.zero_grad()\noptim_ctxt.zero_grad()\noptim_m.zero_grad()\nstart=time.time()\n#Loop over epocs\nfor epoch in range(num_train_epochs):\n    print(\"Epoch \",epoch)\n    #Store average training loss here\n    avg_loss = []\n    #Loop over minibatches\n    for step, batch in enumerate(train_dataloader):\n        #Get the batch\n        context_input, candidate_input, e_ids  = batch\n        \n        longest_cand = torch.max(torch.argmin(candidate_input,dim=1))\n        candidate_input = candidate_input[:,:longest_cand]\n        \n        context_token_idx, context_segment_idx, context_mask = to_bert_input(context_input.to(device),device)\n        candidate_token_idx, candidate_segment_idx, candidate_mask = to_bert_input(candidate_input.to(device),device)\n        #Get representations concerning the cls token\n        context_rep = ctxt_model(context_token_idx, context_segment_idx, context_mask)[0][:,0,:]\n        cand_rep = cand_model(candidate_token_idx, candidate_segment_idx, candidate_mask)[0][:,0,:]\n        \n        #Calculate scores\n        scores = context_rep.mul(cand_rep)\n        scores = m(scores)\n        \n        #Calculate loss for storing\n        loss = torch.nn.functional.cross_entropy(scores, e_ids.to(device))#,weight=torch.tensor(class_weights).to(device))\n        avg_loss.append(loss.item())\n        \n        \n        #Divide loss by grad_acc_steps for backprop\n        loss = loss/grad_acc_steps\n        loss.backward()\n        \n        #Do an update if you have accumulated enough\n        if (step+1)%grad_acc_steps==0:\n            if (step+1)%1000==0:\n              print(\"\\tStep: \",step+1,\" Loss: \",avg_loss[-1],\" Longest Cand: \",longest_cand,\" \",time.time()-start)\n            #Normalize gradients\n            torch.nn.utils.clip_grad_norm_(ctxt_model.parameters(), grad_norm)\n            torch.nn.utils.clip_grad_norm_(cand_model.parameters(), grad_norm)\n            torch.nn.utils.clip_grad_norm_(m.parameters(), grad_norm)\n            #Step the optimizer and scheduler\n            #Reset gradients\n            optim_cand.step()\n            scheduler_cand.step()\n            optim_cand.zero_grad()\n            optim_ctxt.step()\n            optim_ctxt.zero_grad()\n            scheduler_ctxt.step()\n            optim_m.step()\n            scheduler_m.step()\n            optim_m.zero_grad()\n            \n    #Reset gradients at the end of epoch    \n    optim_cand.zero_grad()\n    optim_ctxt.zero_grad()\n    optim_m.zero_grad()\n    #Put model to eval mode\n    ctxt_model.eval()\n    cand_model.eval()\n    m.eval()\n    #This will store validation loss\n    all_loss=0\n    with torch.no_grad():\n        num_correct = 0\n        num_all = 0\n        for step, batch in enumerate(valid_dataloader):\n            context_input, candidate_input, e_ids  = batch\n            \n            longest_cand = torch.max(torch.argmin(candidate_input,dim=1))\n            candidate_input = candidate_input[:,:longest_cand]\n            \n            context_token_idx, context_segment_idx, context_mask = to_bert_input(context_input.to(device),device)\n            candidate_token_idx, candidate_segment_idx, candidate_mask = to_bert_input(candidate_input.to(device),device)\n            context_rep = ctxt_model(context_token_idx, context_segment_idx, context_mask)[0][:,0,:]\n            cand_rep = cand_model(candidate_token_idx, candidate_segment_idx, candidate_mask)[0][:,0,:]\n            scores = context_rep.mul(cand_rep)\n            scores = m(scores)\n            loss = torch.nn.functional.cross_entropy(scores, e_ids.to(device))#,weight=torch.tensor(class_weights).to(device))\n            all_loss+=loss\n            outputs = np.argmax(scores.cpu().detach(), axis=1)\n            outputs = np.sum(outputs.numpy() == e_ids.numpy())\n            num_correct += outputs\n            num_all += context_rep.size(0)\n    all_loss/=len(valid_dataloader)\n    print(\"Val_Loss: \",all_loss)\n    print(\"Val_Acc: \",num_correct/num_all)\n    print(\"Train_loss\",np.mean(avg_loss))\n    ctxt_model.train()\n    cand_model.train()\n    m.train()\n    torch.save(ctxt_model,\"/dbfs/mnt/els-nlp-experts1/data/Gizem/ctxt_model_2_epoch_\"+str(epoch)+\".pt\")\n    torch.save(cand_model,\"/dbfs/mnt/els-nlp-experts1/data/Gizem/cand_model_2_epoch_\"+str(epoch)+\".pt\")\n    torch.save(m,\"/dbfs/mnt/els-nlp-experts1/data/Gizem/m_2_epoch_\"+str(epoch)+\".pt\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fb0a1c6e-7c87-464a-8d5c-b5c496a109c1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Number of steps per epoch:  32650\nNumber of steps with accumulation:  8162\nEpoch  0\n\tStep:  1000  Loss:  0.09248393028974533  Longest Cand:  tensor(45)   814.8776624202728\n\tStep:  2000  Loss:  0.06680081784725189  Longest Cand:  tensor(33)   1599.7708594799042\n\tStep:  3000  Loss:  0.3572031259536743  Longest Cand:  tensor(87)   2415.4179005622864\n\tStep:  4000  Loss:  0.0005756159662269056  Longest Cand:  tensor(77)   3229.002914905548\n\tStep:  5000  Loss:  0.006526140496134758  Longest Cand:  tensor(64)   4028.166960000992\n\tStep:  6000  Loss:  0.005424450617283583  Longest Cand:  tensor(66)   4827.6773471832275\n\tStep:  7000  Loss:  0.0479513555765152  Longest Cand:  tensor(254)   5629.051876544952\n\tStep:  8000  Loss:  0.006215271074324846  Longest Cand:  tensor(44)   6421.839501619339\n\tStep:  9000  Loss:  0.01775495894253254  Longest Cand:  tensor(77)   7214.209529876709\n\tStep:  10000  Loss:  0.16591501235961914  Longest Cand:  tensor(52)   8014.593359470367\n\tStep:  11000  Loss:  0.003354735439643264  Longest Cand:  tensor(73)   8802.930846691132\n\tStep:  12000  Loss:  0.2651071548461914  Longest Cand:  tensor(31)   9611.902805566788\n\tStep:  13000  Loss:  0.028736621141433716  Longest Cand:  tensor(59)   10405.423636674881\n\tStep:  14000  Loss:  0.0054207430221140385  Longest Cand:  tensor(118)   11203.462766885757\n\tStep:  15000  Loss:  0.01050422340631485  Longest Cand:  tensor(86)   12005.531960487366\n\tStep:  16000  Loss:  0.0007775490521453321  Longest Cand:  tensor(77)   12813.463909626007\n\tStep:  17000  Loss:  0.10401599854230881  Longest Cand:  tensor(87)   13605.17962217331\n\tStep:  18000  Loss:  0.04240906238555908  Longest Cand:  tensor(86)   14396.939082622528\n\tStep:  19000  Loss:  0.1139596551656723  Longest Cand:  tensor(93)   15199.983484268188\n\tStep:  20000  Loss:  0.0419851653277874  Longest Cand:  tensor(255)   15997.333102941513\n\tStep:  21000  Loss:  0.013749810867011547  Longest Cand:  tensor(78)   16786.059148788452\n\tStep:  22000  Loss:  0.0754447877407074  Longest Cand:  tensor(59)   17591.140445947647\n\tStep:  23000  Loss:  0.01861928030848503  Longest Cand:  tensor(58)   18399.203429937363\n\tStep:  24000  Loss:  0.012988919392228127  Longest Cand:  tensor(82)   19220.785907030106\n\tStep:  25000  Loss:  0.12007538974285126  Longest Cand:  tensor(52)   20024.225303411484\n\tStep:  26000  Loss:  0.059678222984075546  Longest Cand:  tensor(77)   20824.68920135498\n\tStep:  27000  Loss:  0.006149991415441036  Longest Cand:  tensor(47)   21644.099066495895\n\tStep:  28000  Loss:  0.004282450303435326  Longest Cand:  tensor(242)   22445.217373609543\n\tStep:  29000  Loss:  0.011113166809082031  Longest Cand:  tensor(27)   23249.12618637085\n\tStep:  30000  Loss:  0.009378837421536446  Longest Cand:  tensor(77)   24046.88488292694\n\tStep:  31000  Loss:  0.014974141493439674  Longest Cand:  tensor(40)   24859.486727952957\n\tStep:  32000  Loss:  0.12184242159128189  Longest Cand:  tensor(77)   25664.963148593903\nVal_Loss:  tensor(0.0534, device=&#39;cuda:0&#39;)\nVal_Acc:  0.9818391943206207\nTrain_loss 0.06417036106665794\nEpoch  1\n\tStep:  1000  Loss:  0.010409155860543251  Longest Cand:  tensor(72)   28100.14659690857\n\tStep:  2000  Loss:  0.04791463539004326  Longest Cand:  tensor(56)   28902.801854133606\n\tStep:  3000  Loss:  0.0011382988886907697  Longest Cand:  tensor(40)   29709.69136095047\n\tStep:  4000  Loss:  0.008210109546780586  Longest Cand:  tensor(70)   30490.995913267136\n\tStep:  5000  Loss:  0.0008776619215495884  Longest Cand:  tensor(77)   31281.353591918945\n\tStep:  6000  Loss:  0.009233826771378517  Longest Cand:  tensor(77)   32087.97818017006\n\tStep:  7000  Loss:  0.002257788786664605  Longest Cand:  tensor(30)   32905.01256775856\n\tStep:  8000  Loss:  0.005547088570892811  Longest Cand:  tensor(133)   33700.380135297775\n\tStep:  9000  Loss:  0.23985807597637177  Longest Cand:  tensor(118)   34479.31267786026\n\tStep:  10000  Loss:  0.0034057889133691788  Longest Cand:  tensor(64)   35264.025430202484\n\tStep:  11000  Loss:  0.003400163259357214  Longest Cand:  tensor(69)   36070.82172751427\n\tStep:  12000  Loss:  0.005186920054256916  Longest Cand:  tensor(82)   36878.161945819855\n\tStep:  13000  Loss:  0.006035883445292711  Longest Cand:  tensor(255)   37680.18316245079\n\tStep:  14000  Loss:  0.02868935838341713  Longest Cand:  tensor(118)   38470.94439649582\n\tStep:  15000  Loss:  0.0047598122619092464  Longest Cand:  tensor(238)   39287.56216096878\n\tStep:  16000  Loss:  0.13151416182518005  Longest Cand:  tensor(55)   40091.147406339645\n\tStep:  17000  Loss:  0.015800513327121735  Longest Cand:  tensor(133)   40896.53985905647\n\tStep:  18000  Loss:  0.03297416865825653  Longest Cand:  tensor(53)   41702.09716773033\n\tStep:  19000  Loss:  0.002290937816724181  Longest Cand:  tensor(255)   42487.72639918327\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Number of steps per epoch:  32650\nNumber of steps with accumulation:  8162\nEpoch  0\n\tStep:  1000  Loss:  0.09248393028974533  Longest Cand:  tensor(45)   814.8776624202728\n\tStep:  2000  Loss:  0.06680081784725189  Longest Cand:  tensor(33)   1599.7708594799042\n\tStep:  3000  Loss:  0.3572031259536743  Longest Cand:  tensor(87)   2415.4179005622864\n\tStep:  4000  Loss:  0.0005756159662269056  Longest Cand:  tensor(77)   3229.002914905548\n\tStep:  5000  Loss:  0.006526140496134758  Longest Cand:  tensor(64)   4028.166960000992\n\tStep:  6000  Loss:  0.005424450617283583  Longest Cand:  tensor(66)   4827.6773471832275\n\tStep:  7000  Loss:  0.0479513555765152  Longest Cand:  tensor(254)   5629.051876544952\n\tStep:  8000  Loss:  0.006215271074324846  Longest Cand:  tensor(44)   6421.839501619339\n\tStep:  9000  Loss:  0.01775495894253254  Longest Cand:  tensor(77)   7214.209529876709\n\tStep:  10000  Loss:  0.16591501235961914  Longest Cand:  tensor(52)   8014.593359470367\n\tStep:  11000  Loss:  0.003354735439643264  Longest Cand:  tensor(73)   8802.930846691132\n\tStep:  12000  Loss:  0.2651071548461914  Longest Cand:  tensor(31)   9611.902805566788\n\tStep:  13000  Loss:  0.028736621141433716  Longest Cand:  tensor(59)   10405.423636674881\n\tStep:  14000  Loss:  0.0054207430221140385  Longest Cand:  tensor(118)   11203.462766885757\n\tStep:  15000  Loss:  0.01050422340631485  Longest Cand:  tensor(86)   12005.531960487366\n\tStep:  16000  Loss:  0.0007775490521453321  Longest Cand:  tensor(77)   12813.463909626007\n\tStep:  17000  Loss:  0.10401599854230881  Longest Cand:  tensor(87)   13605.17962217331\n\tStep:  18000  Loss:  0.04240906238555908  Longest Cand:  tensor(86)   14396.939082622528\n\tStep:  19000  Loss:  0.1139596551656723  Longest Cand:  tensor(93)   15199.983484268188\n\tStep:  20000  Loss:  0.0419851653277874  Longest Cand:  tensor(255)   15997.333102941513\n\tStep:  21000  Loss:  0.013749810867011547  Longest Cand:  tensor(78)   16786.059148788452\n\tStep:  22000  Loss:  0.0754447877407074  Longest Cand:  tensor(59)   17591.140445947647\n\tStep:  23000  Loss:  0.01861928030848503  Longest Cand:  tensor(58)   18399.203429937363\n\tStep:  24000  Loss:  0.012988919392228127  Longest Cand:  tensor(82)   19220.785907030106\n\tStep:  25000  Loss:  0.12007538974285126  Longest Cand:  tensor(52)   20024.225303411484\n\tStep:  26000  Loss:  0.059678222984075546  Longest Cand:  tensor(77)   20824.68920135498\n\tStep:  27000  Loss:  0.006149991415441036  Longest Cand:  tensor(47)   21644.099066495895\n\tStep:  28000  Loss:  0.004282450303435326  Longest Cand:  tensor(242)   22445.217373609543\n\tStep:  29000  Loss:  0.011113166809082031  Longest Cand:  tensor(27)   23249.12618637085\n\tStep:  30000  Loss:  0.009378837421536446  Longest Cand:  tensor(77)   24046.88488292694\n\tStep:  31000  Loss:  0.014974141493439674  Longest Cand:  tensor(40)   24859.486727952957\n\tStep:  32000  Loss:  0.12184242159128189  Longest Cand:  tensor(77)   25664.963148593903\nVal_Loss:  tensor(0.0534, device=&#39;cuda:0&#39;)\nVal_Acc:  0.9818391943206207\nTrain_loss 0.06417036106665794\nEpoch  1\n\tStep:  1000  Loss:  0.010409155860543251  Longest Cand:  tensor(72)   28100.14659690857\n\tStep:  2000  Loss:  0.04791463539004326  Longest Cand:  tensor(56)   28902.801854133606\n\tStep:  3000  Loss:  0.0011382988886907697  Longest Cand:  tensor(40)   29709.69136095047\n\tStep:  4000  Loss:  0.008210109546780586  Longest Cand:  tensor(70)   30490.995913267136\n\tStep:  5000  Loss:  0.0008776619215495884  Longest Cand:  tensor(77)   31281.353591918945\n\tStep:  6000  Loss:  0.009233826771378517  Longest Cand:  tensor(77)   32087.97818017006\n\tStep:  7000  Loss:  0.002257788786664605  Longest Cand:  tensor(30)   32905.01256775856\n\tStep:  8000  Loss:  0.005547088570892811  Longest Cand:  tensor(133)   33700.380135297775\n\tStep:  9000  Loss:  0.23985807597637177  Longest Cand:  tensor(118)   34479.31267786026\n\tStep:  10000  Loss:  0.0034057889133691788  Longest Cand:  tensor(64)   35264.025430202484\n\tStep:  11000  Loss:  0.003400163259357214  Longest Cand:  tensor(69)   36070.82172751427\n\tStep:  12000  Loss:  0.005186920054256916  Longest Cand:  tensor(82)   36878.161945819855\n\tStep:  13000  Loss:  0.006035883445292711  Longest Cand:  tensor(255)   37680.18316245079\n\tStep:  14000  Loss:  0.02868935838341713  Longest Cand:  tensor(118)   38470.94439649582\n\tStep:  15000  Loss:  0.0047598122619092464  Longest Cand:  tensor(238)   39287.56216096878\n\tStep:  16000  Loss:  0.13151416182518005  Longest Cand:  tensor(55)   40091.147406339645\n\tStep:  17000  Loss:  0.015800513327121735  Longest Cand:  tensor(133)   40896.53985905647\n\tStep:  18000  Loss:  0.03297416865825653  Longest Cand:  tensor(53)   41702.09716773033\n\tStep:  19000  Loss:  0.002290937816724181  Longest Cand:  tensor(255)   42487.72639918327\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"Cancelled","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"93e43a58-843f-4ab8-aa8e-ba41f09fbcc2"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"BiEncoderHardNeg","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3257438}},"nbformat":4,"nbformat_minor":0}
