{"cells":[{"cell_type":"code","source":["%pip install transformers==3.5.1"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3deaf16c-e86d-4da6-b57d-602d78823eeb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting transformers==3.5.1\n  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\nCollecting tokenizers==0.9.3\n  Downloading tokenizers-0.9.3-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\nRequirement already satisfied: requests in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from transformers==3.5.1) (2.24.0)\nCollecting sentencepiece==0.1.91\n  Downloading sentencepiece-0.1.91-cp38-cp38-manylinux1_x86_64.whl (1.1 MB)\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from transformers==3.5.1) (2020.10.15)\nRequirement already satisfied: protobuf in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from transformers==3.5.1) (3.13.0)\nRequirement already satisfied: tqdm&gt;=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from transformers==3.5.1) (4.50.2)\nCollecting sacremoses\n  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\nRequirement already satisfied: packaging in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from transformers==3.5.1) (20.4)\nCollecting filelock\n  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from transformers==3.5.1) (1.19.2)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (2.10)\nRequirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (3.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (2020.12.5)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (1.25.11)\nRequirement already satisfied: six&gt;=1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from protobuf-&gt;transformers==3.5.1) (1.15.0)\nRequirement already satisfied: setuptools in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from protobuf-&gt;transformers==3.5.1) (50.3.1.post20201107)\nRequirement already satisfied: click in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (7.1.2)\nRequirement already satisfied: joblib in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (0.17.0)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from packaging-&gt;transformers==3.5.1) (2.4.7)\nInstalling collected packages: tokenizers, sentencepiece, sacremoses, filelock, transformers\nSuccessfully installed filelock-3.0.12 sacremoses-0.0.45 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting transformers==3.5.1\n  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\nCollecting tokenizers==0.9.3\n  Downloading tokenizers-0.9.3-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\nRequirement already satisfied: requests in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from transformers==3.5.1) (2.24.0)\nCollecting sentencepiece==0.1.91\n  Downloading sentencepiece-0.1.91-cp38-cp38-manylinux1_x86_64.whl (1.1 MB)\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from transformers==3.5.1) (2020.10.15)\nRequirement already satisfied: protobuf in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from transformers==3.5.1) (3.13.0)\nRequirement already satisfied: tqdm&gt;=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from transformers==3.5.1) (4.50.2)\nCollecting sacremoses\n  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\nRequirement already satisfied: packaging in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from transformers==3.5.1) (20.4)\nCollecting filelock\n  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from transformers==3.5.1) (1.19.2)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (2.10)\nRequirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (3.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (2020.12.5)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from requests-&gt;transformers==3.5.1) (1.25.11)\nRequirement already satisfied: six&gt;=1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from protobuf-&gt;transformers==3.5.1) (1.15.0)\nRequirement already satisfied: setuptools in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from protobuf-&gt;transformers==3.5.1) (50.3.1.post20201107)\nRequirement already satisfied: click in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (7.1.2)\nRequirement already satisfied: joblib in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from sacremoses-&gt;transformers==3.5.1) (0.17.0)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-45db5c28-66df-4d12-be5a-b6f32bfa0ad9/lib/python3.8/site-packages (from packaging-&gt;transformers==3.5.1) (2.4.7)\nInstalling collected packages: tokenizers, sentencepiece, sacremoses, filelock, transformers\nSuccessfully installed filelock-3.0.12 sacremoses-0.0.45 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import random\nimport torch\nimport time\nimport numpy as np\nimport pickle\nimport json\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\nfrom transformers import get_linear_schedule_with_warmup,BertTokenizerFast, BertModel"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1fcc29e0-0ed5-435a-a214-29b3156529f1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["INP_PATH = \"/dbfs/mnt/els-nlp-experts1/data/Gizem/\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"59074b5d-b6fd-423c-b0dc-3eee5fa50edd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["##FROM THE BLINK REPO##\nENT_START_TAG = \"[unused0]\"\nENT_END_TAG = \"[unused1]\"\n\ndef select_field(data, key1, key2=None):\n    if key2 is None:\n        return [example[key1] for example in data]\n    else:\n        return [example[key1][key2] for example in data]\n\ndef get_context_representation(\n    sample,\n    tokenizer,\n    max_seq_length,\n    mention_key=\"mention\",\n    context_key=\"context\",\n    ent_start_token=ENT_START_TAG,\n    ent_end_token=ENT_END_TAG,\n):\n    # mention_tokens = [Ms] mention [Me]\n    mention_tokens = []\n    if sample[mention_key] and len(sample[mention_key]) > 0:\n        mention_tokens = tokenizer.tokenize(sample[mention_key])\n        mention_tokens = [ent_start_token] + mention_tokens + [ent_end_token]\n\n    context_left = sample[context_key + \"_left\"]\n    context_right = sample[context_key + \"_right\"]\n    context_left = tokenizer.tokenize(context_left)\n    context_right = tokenizer.tokenize(context_right)\n\n    left_quota = (max_seq_length - len(mention_tokens)) // 2 - 1\n    right_quota = max_seq_length - len(mention_tokens) - left_quota - 2\n    left_add = len(context_left)\n    right_add = len(context_right)\n    if left_add <= left_quota:\n        if right_add > right_quota:\n            right_quota += left_quota - left_add\n    else:\n        if right_add <= right_quota:\n            left_quota += right_quota - right_add\n    \n    context_tokens = (\n        context_left[-left_quota:] + mention_tokens + context_right[:right_quota]\n    )\n    \n    # mention_tokens = [CLS] left context [Ms] mention [Me] right context [SEP]\n    context_tokens = [\"[CLS]\"] + context_tokens + [\"[SEP]\"]\n    input_ids = tokenizer.convert_tokens_to_ids(context_tokens)\n    padding = [0] * (max_seq_length - len(input_ids))\n    input_ids += padding\n    assert len(input_ids) == max_seq_length\n\n    return {\n        \"tokens\": context_tokens,\n        \"ids\": input_ids,\n    }\n\n\ndef get_candidate_representation(label_idx):\n\n    cand_tokens = entity_dict[str(label_idx)]['tokens']\n    input_ids = entity_dict[str(label_idx)]['ids']\n    \n    return {\n        \"tokens\": cand_tokens,\n        \"ids\": input_ids,\n    }\n  \ndef to_bert_input(token_idx,dev_name):\n    \"\"\" token_idx is a 2D tensor int.\n        return token_idx, segment_idx and mask\n    \"\"\"\n    segment_idx = None\n    mask = token_idx != 0\n    if dev_name =='cuda':\n        segment_idx = torch.cuda.LongTensor(token_idx * 0)\n        mask = torch.cuda.LongTensor(mask.long())\n    else:\n        segment_idx = torch.LongTensor(token_idx * 0)\n        mask = torch.LongTensor(mask.long())    \n    return token_idx, segment_idx, mask"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fd135806-4ac0-408e-b858-8d0c95790ab1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def process_mention_data(\n    samples,\n    tokenizer,\n    max_context_length,\n    max_cand_length,\n    mention_key=\"mention\",\n    context_key=\"context\",\n    ent_start_token=ENT_START_TAG,\n    ent_end_token=ENT_END_TAG\n):\n    processed_samples = []\n    iter_ = samples\n    all_samples = []\n\n    for idx, sample in enumerate(iter_):\n        context_tokens = get_context_representation(\n            sample,\n            tokenizer,\n            max_context_length,\n            mention_key,\n            context_key,\n            ent_start_token,\n            ent_end_token,\n        )\n        \n        if len(sample[\"negative_cands\"]) != num_neg_cands:\n          #NIL mention\n          pass\n        else:\n          label_idx = int(sample[\"label_id\"])\n          label_tokens = get_candidate_representation(label_idx)\n          \n          record = {\n              \"context\": context_tokens,\n              \"label\": label_tokens,\n              \"label_idx\": 1,\n              \"sample\":sample\n          }\n          processed_samples.append(record)\n          all_samples.append(sample)\n        \n        for label_idx in sample[\"negative_cands\"]:\n            label_tokens = get_candidate_representation(label_idx)\n            record = {\n                \"context\": context_tokens,\n                \"label\": label_tokens,\n                \"label_idx\": 0,\n                \"sample\":sample\n            }\n            processed_samples.append(record)\n            all_samples.append(sample)\n        \n    context_vecs = torch.tensor(\n        select_field(processed_samples, \"context\", \"ids\"), dtype=torch.long,\n    )\n    cand_vecs = torch.tensor(\n        select_field(processed_samples, \"label\", \"ids\"), dtype=torch.long,\n    )\n    label_idx = torch.tensor(\n        select_field(processed_samples, \"label_idx\"), dtype=torch.long,\n    )\n    data = {\n        \"context_vecs\": context_vecs,\n        \"cand_vecs\": cand_vecs,\n        \"label_idx\": label_idx,\n        \"sample\":all_samples\n    }\n\n    tensor_data = TensorDataset(context_vecs, cand_vecs, label_idx)\n    return data, tensor_data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99415d2c-1e8d-4867-8ff2-659b99428c09"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["seed = 0\ndevice = 'cuda'\nbase_bert_model = '/dbfs/mnt/els-nlp-experts1/data/Gizem/bert-base-cased-tapt3/checkpoint-1000'\ntrain_fname = INP_PATH+\"train_all.jsonl\"\nmonitor_fname = INP_PATH+\"monitor_all.jsonl\"\nmax_context_length= 64\ntrain_batch_size = 16\nnum_train_epochs=2\neval_batch_size= 256\ngrad_acc_steps= 4\nclass_weights = [0.25,0.75]\nnum_neg_cands=3\ngrad_norm = 1.0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a7f299cf-28b4-40fc-9ea4-d25b35b30414"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["max_cand_length = 256\nwith open(INP_PATH+'entities_256.pkl','rb') as f:\n    entity_dict=pickle.load(f)\n    \nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7210949-33bc-4492-9a74-65abf8b095ba"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[7]: &lt;torch._C.Generator at 0x7f4a24059f10&gt;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[7]: &lt;torch._C.Generator at 0x7f4a24059f10&gt;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["ctxt_model = BertModel.from_pretrained(base_bert_model).to(device)\ncand_model = BertModel.from_pretrained(base_bert_model).to(device)\nm = torch.nn.Linear(768, 2,bias=False).to(device)\ntokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d61f7cd0-4299-4ed4-ba36-7bf12393cea8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Some weights of BertModel were not initialized from the model checkpoint at /dbfs/mnt/els-nlp-experts1/data/Gizem/bert-base-cased-tapt3/checkpoint-1000 and are newly initialized: [&#39;bert.pooler.dense.weight&#39;, &#39;bert.pooler.dense.bias&#39;]\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertModel were not initialized from the model checkpoint at /dbfs/mnt/els-nlp-experts1/data/Gizem/bert-base-cased-tapt3/checkpoint-1000 and are newly initialized: [&#39;bert.pooler.dense.weight&#39;, &#39;bert.pooler.dense.bias&#39;]\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\rDownloading:   0%|          | 0.00/213k [00:00&lt;?, ?B/s]\rDownloading: 100%|██████████| 213k/213k [00:00&lt;00:00, 31.2MB/s]\n\rDownloading:   0%|          | 0.00/436k [00:00&lt;?, ?B/s]\rDownloading: 100%|██████████| 436k/436k [00:00&lt;00:00, 33.8MB/s]\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Some weights of BertModel were not initialized from the model checkpoint at /dbfs/mnt/els-nlp-experts1/data/Gizem/bert-base-cased-tapt3/checkpoint-1000 and are newly initialized: [&#39;bert.pooler.dense.weight&#39;, &#39;bert.pooler.dense.bias&#39;]\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertModel were not initialized from the model checkpoint at /dbfs/mnt/els-nlp-experts1/data/Gizem/bert-base-cased-tapt3/checkpoint-1000 and are newly initialized: [&#39;bert.pooler.dense.weight&#39;, &#39;bert.pooler.dense.bias&#39;]\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\rDownloading:   0%|          | 0.00/213k [00:00&lt;?, ?B/s]\rDownloading: 100%|██████████| 213k/213k [00:00&lt;00:00, 31.2MB/s]\n\rDownloading:   0%|          | 0.00/436k [00:00&lt;?, ?B/s]\rDownloading: 100%|██████████| 436k/436k [00:00&lt;00:00, 33.8MB/s]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Load train data \ntrain_samples = []\nwith open(train_fname, mode=\"r\", encoding=\"utf-8\") as file:\n    for line in file:\n        train_samples.append(json.loads(line.strip()))\nprint(len(train_samples))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"929a9bde-f2db-47e1-9cee-30ea1f225512"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">95761\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">95761\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["for i in range(len(train_samples)):\n    if i%1000==0:\n      print(i)\n    this_neg_cand = num_neg_cands\n    e_ids = list(entity_dict.keys())\n    neg_samples = None\n    if train_samples[i]['label_id'] is not None:\n      e_ids.remove(train_samples[i]['label_id'])\n      neg_samples = np.random.choice(e_ids,num_neg_cands,replace=False)\n    else:\n      #NIL mention\n      neg_samples = np.random.choice(e_ids,num_neg_cands+1,replace=False)\n    neg_samples = [int(x) for x in neg_samples]\n    train_samples[i]['negative_cands'] = neg_samples"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3796412e-2b7b-48fe-86fb-d7a255bf3423"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n11000\n12000\n13000\n14000\n15000\n16000\n17000\n18000\n19000\n20000\n21000\n22000\n23000\n24000\n25000\n26000\n27000\n28000\n29000\n30000\n31000\n32000\n33000\n34000\n35000\n36000\n37000\n38000\n39000\n40000\n41000\n42000\n43000\n44000\n45000\n46000\n47000\n48000\n49000\n50000\n51000\n52000\n53000\n54000\n55000\n56000\n57000\n58000\n59000\n60000\n61000\n62000\n63000\n64000\n65000\n66000\n67000\n68000\n69000\n70000\n71000\n72000\n73000\n74000\n75000\n76000\n77000\n78000\n79000\n80000\n81000\n82000\n83000\n84000\n85000\n86000\n87000\n88000\n89000\n90000\n91000\n92000\n93000\n94000\n95000\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n11000\n12000\n13000\n14000\n15000\n16000\n17000\n18000\n19000\n20000\n21000\n22000\n23000\n24000\n25000\n26000\n27000\n28000\n29000\n30000\n31000\n32000\n33000\n34000\n35000\n36000\n37000\n38000\n39000\n40000\n41000\n42000\n43000\n44000\n45000\n46000\n47000\n48000\n49000\n50000\n51000\n52000\n53000\n54000\n55000\n56000\n57000\n58000\n59000\n60000\n61000\n62000\n63000\n64000\n65000\n66000\n67000\n68000\n69000\n70000\n71000\n72000\n73000\n74000\n75000\n76000\n77000\n78000\n79000\n80000\n81000\n82000\n83000\n84000\n85000\n86000\n87000\n88000\n89000\n90000\n91000\n92000\n93000\n94000\n95000\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["train_data, train_tensor_data = process_mention_data(\n    train_samples,\n    tokenizer,\n    max_context_length,\n    max_cand_length\n)\n\ntrain_sampler = RandomSampler(train_tensor_data)\ntrain_dataloader = DataLoader(train_tensor_data, sampler=train_sampler, batch_size=train_batch_size)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"694ac014-0a17-4549-a41a-2984df8aed23"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Load eval data\nvalid_samples = []\nwith open(monitor_fname, mode=\"r\", encoding=\"utf-8\") as file:\n    for line in file:\n        valid_samples.append(json.loads(line.strip()))\nprint(len(valid_samples))\nfor i in range(len(valid_samples)):\n    if i%1000==0:\n      print(i)\n    this_neg_cand = num_neg_cands\n    e_ids = list(entity_dict.keys())\n    neg_samples = None\n    if valid_samples[i]['label_id'] is not None:\n      e_ids.remove(valid_samples[i]['label_id'])\n      neg_samples = np.random.choice(e_ids,num_neg_cands,replace=False)\n    else:\n      #NIL mention\n      neg_samples = np.random.choice(e_ids,num_neg_cands+1,replace=False)\n    neg_samples = [int(x) for x in neg_samples]\n    valid_samples[i]['negative_cands'] = neg_samples\n\nvalid_data, valid_tensor_data = process_mention_data(\n    valid_samples,\n    tokenizer,\n    max_context_length,\n    max_cand_length\n)\nvalid_sampler = SequentialSampler(valid_tensor_data)\nvalid_dataloader = DataLoader(valid_tensor_data, sampler=valid_sampler, batch_size=eval_batch_size)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e25c748d-4546-4a67-a839-2593c8a3dc84"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">5618\n0\n1000\n2000\n3000\n4000\n5000\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">5618\n0\n1000\n2000\n3000\n4000\n5000\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["optim_cand = torch.optim.AdamW(cand_model.parameters(), lr=2e-5) \nscheduler_cand = get_linear_schedule_with_warmup(optim_cand, \n                                                 num_warmup_steps = 0, \n                                                 num_training_steps = len(train_dataloader) // grad_acc_steps * num_train_epochs)\noptim_ctxt = torch.optim.AdamW(ctxt_model.parameters(), lr=2e-5) \nscheduler_ctxt = get_linear_schedule_with_warmup(optim_ctxt, \n                                                 num_warmup_steps = 0, \n                                                 num_training_steps = len(train_dataloader) // grad_acc_steps * num_train_epochs)\noptim_m = torch.optim.AdamW(m.parameters(), lr=2e-5) \nscheduler_m = get_linear_schedule_with_warmup(optim_m, \n                                                 num_warmup_steps = 0, \n                                                 num_training_steps = len(train_dataloader) // grad_acc_steps * num_train_epochs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8f00d6d-40d4-46ec-83a0-b10a11c56adb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["ctxt_model.eval()\ncand_model.eval()\nm.eval()\nall_loss=0\nprint(\"Number of steps: \",len(valid_dataloader))\nwith torch.no_grad():\n    num_correct = 0\n    num_all = 0\n    for step, batch in enumerate(valid_dataloader):\n\n        context_input, candidate_input, e_ids  = batch\n        longest_cand = torch.max(torch.argmin(candidate_input,dim=1))\n        candidate_input = candidate_input[:,:longest_cand]\n        \n        if step%10==0:\n            print(\"Step:\",step,\" longest cand \",longest_cand)\n            \n        context_token_idx, context_segment_idx, context_mask = to_bert_input(context_input.to(device),device)\n        candidate_token_idx, candidate_segment_idx, candidate_mask = to_bert_input(candidate_input.to(device),device)\n        \n        context_rep = ctxt_model(context_token_idx, context_segment_idx, context_mask)[0][:,0,:]\n        cand_rep = cand_model(candidate_token_idx, candidate_segment_idx, candidate_mask)[0][:,0,:]\n        \n        scores = context_rep.mul(cand_rep)\n        scores = m(scores)\n        \n        loss = torch.nn.functional.cross_entropy(scores, e_ids.to(device),weight=torch.tensor(class_weights).to(device))\n        all_loss+=loss\n        outputs = np.argmax(scores.cpu().detach(), axis=1)\n        outputs = np.sum(outputs.numpy() == e_ids.numpy())\n        num_correct += outputs\n        num_all += context_rep.size(0)\nall_loss/=len(valid_dataloader)\nprint(\"Val_Loss: \",all_loss)\nprint(\"Val_Acc: \",num_correct/num_all)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e328ca16-7aa3-4f50-bc5d-035c80429190"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Number of steps:  88\nStep: 0  longest cand  tensor(113)\nStep: 10  longest cand  tensor(190)\nStep: 20  longest cand  tensor(193)\nStep: 30  longest cand  tensor(107)\nStep: 40  longest cand  tensor(255)\nStep: 50  longest cand  tensor(227)\nStep: 60  longest cand  tensor(237)\nStep: 70  longest cand  tensor(238)\nStep: 80  longest cand  tensor(215)\nVal_Loss:  tensor(1.6341, device=&#39;cuda:0&#39;)\nVal_Acc:  0.7886703453186187\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Number of steps:  88\nStep: 0  longest cand  tensor(113)\nStep: 10  longest cand  tensor(190)\nStep: 20  longest cand  tensor(193)\nStep: 30  longest cand  tensor(107)\nStep: 40  longest cand  tensor(255)\nStep: 50  longest cand  tensor(227)\nStep: 60  longest cand  tensor(237)\nStep: 70  longest cand  tensor(238)\nStep: 80  longest cand  tensor(215)\nVal_Loss:  tensor(1.6341, device=&#39;cuda:0&#39;)\nVal_Acc:  0.7886703453186187\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["ctxt_model.train()\ncand_model.train()\nm.train()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28c5cb69-9d8e-4fe5-98d7-660abeccc443"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[15]: Linear(in_features=768, out_features=2, bias=False)</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[15]: Linear(in_features=768, out_features=2, bias=False)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["print('Number of steps per epoch: ',len(train_dataloader))\nprint('Number of steps with accumulation: ',len(train_dataloader)//grad_acc_steps)\n\n#Reset Gradients\noptim_cand.zero_grad()\noptim_ctxt.zero_grad()\noptim_m.zero_grad()\nstart=time.time()\n#Loop over epocs\nfor epoch in range(num_train_epochs):\n    print(\"Epoch \",epoch)\n    #Store average training loss here\n    avg_loss = []\n    #Loop over minibatches\n    for step, batch in enumerate(train_dataloader):\n        #Get the batch\n        context_input, candidate_input, e_ids  = batch\n        \n        longest_cand = torch.max(torch.argmin(candidate_input,dim=1))\n        candidate_input = candidate_input[:,:longest_cand]\n        \n        context_token_idx, context_segment_idx, context_mask = to_bert_input(context_input.to(device),device)\n        candidate_token_idx, candidate_segment_idx, candidate_mask = to_bert_input(candidate_input.to(device),device)\n        #Get representations concerning the cls token\n        context_rep = ctxt_model(context_token_idx, context_segment_idx, context_mask)[0][:,0,:]\n        cand_rep = cand_model(candidate_token_idx, candidate_segment_idx, candidate_mask)[0][:,0,:]\n        \n        #Calculate scores\n        scores = context_rep.mul(cand_rep)\n        scores = m(scores)\n        \n        #Calculate loss for storing\n        loss = torch.nn.functional.cross_entropy(scores, e_ids.to(device),weight=torch.tensor(class_weights).to(device))\n        avg_loss.append(loss.item())\n        \n        \n        #Divide loss by grad_acc_steps for backprop\n        loss = loss/grad_acc_steps\n        loss.backward()\n        \n        #Do an update if you have accumulated enough\n        if (step+1)%grad_acc_steps==0:\n            if (step+1)%3000==0:\n              print(\"\\tStep: \",step+1,\" Loss: \",avg_loss[-1],\" Longest Cand: \",longest_cand,\" \",time.time()-start)\n            #Normalize gradients\n            torch.nn.utils.clip_grad_norm_(ctxt_model.parameters(), grad_norm)\n            torch.nn.utils.clip_grad_norm_(cand_model.parameters(), grad_norm)\n            torch.nn.utils.clip_grad_norm_(m.parameters(), grad_norm)\n            #Step the optimizer and scheduler\n            #Reset gradients\n            optim_cand.step()\n            scheduler_cand.step()\n            optim_cand.zero_grad()\n            optim_ctxt.step()\n            optim_ctxt.zero_grad()\n            scheduler_ctxt.step()\n            optim_m.step()\n            scheduler_m.step()\n            optim_m.zero_grad()\n            \n    #Reset gradients at the end of epoch    \n    optim_cand.zero_grad()\n    optim_ctxt.zero_grad()\n    optim_m.zero_grad()\n    #Put model to eval mode\n    ctxt_model.eval()\n    cand_model.eval()\n    m.eval()\n    #This will store validation loss\n    all_loss=0\n    with torch.no_grad():\n        num_correct = 0\n        num_all = 0\n        for step, batch in enumerate(valid_dataloader):\n            context_input, candidate_input, e_ids  = batch\n            \n            longest_cand = torch.max(torch.argmin(candidate_input,dim=1))\n            candidate_input = candidate_input[:,:longest_cand]\n            \n            context_token_idx, context_segment_idx, context_mask = to_bert_input(context_input.to(device),device)\n            candidate_token_idx, candidate_segment_idx, candidate_mask = to_bert_input(candidate_input.to(device),device)\n            context_rep = ctxt_model(context_token_idx, context_segment_idx, context_mask)[0][:,0,:]\n            cand_rep = cand_model(candidate_token_idx, candidate_segment_idx, candidate_mask)[0][:,0,:]\n            scores = context_rep.mul(cand_rep)\n            scores = m(scores)\n            loss = torch.nn.functional.cross_entropy(scores, e_ids.to(device),weight=torch.tensor(class_weights).to(device))\n            all_loss+=loss\n            outputs = np.argmax(scores.cpu().detach(), axis=1)\n            outputs = np.sum(outputs.numpy() == e_ids.numpy())\n            num_correct += outputs\n            num_all += context_rep.size(0)\n    all_loss/=len(valid_dataloader)\n    print(\"Val_Loss: \",all_loss)\n    print(\"Val_Acc: \",num_correct/num_all)\n    print(\"Train_loss\",np.mean(avg_loss))\n    ctxt_model.train()\n    cand_model.train()\n    m.train()\n    torch.save(ctxt_model,\"/dbfs/mnt/els-nlp-experts1/data/Gizem/randomneg_ctxt_model_epoch_\"+str(epoch)+\".pt\")\n    torch.save(cand_model,\"/dbfs/mnt/els-nlp-experts1/data/Gizem/randomneg_cand_model_epoch_\"+str(epoch)+\".pt\")\n    torch.save(m,\"/dbfs/mnt/els-nlp-experts1/data/Gizem/randomneg_m_epoch_\"+str(epoch)+\".pt\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fb0a1c6e-7c87-464a-8d5c-b5c496a109c1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Number of steps per epoch:  23941\nNumber of steps with accumulation:  5985\nEpoch  0\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Number of steps per epoch:  23941\nNumber of steps with accumulation:  5985\nEpoch  0\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13a74d14-0c6c-4edf-bd10-b10f8b8acbd9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"BiEncoderRandomNeg","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3254413}},"nbformat":4,"nbformat_minor":0}
