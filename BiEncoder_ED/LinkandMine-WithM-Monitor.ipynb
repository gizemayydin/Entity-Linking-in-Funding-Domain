{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from tqdm import trange\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from biencoder import *\n",
    "import data_process as data\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import  BertTokenizerFast, BertModel\n",
    "from queue import PriorityQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_folder = \"entity_embdes_2.pkl\"\n",
    "input_batch_size = 256\n",
    "model_path = 'C:\\\\Users\\\\aydxng\\\\Documents\\\\ds-fundingbodies-linkingcomponent-masterthesis\\\\Thesis\\\\LinkerRound1\\\\ctxt_model_2_epoch_0.pt'\n",
    "model_path_m = 'C:\\\\Users\\\\aydxng\\\\Documents\\\\ds-fundingbodies-linkingcomponent-masterthesis\\\\Thesis\\\\LinkerRound1\\\\m_2_epoch_0.pt'\n",
    "seed = 0\n",
    "device='cuda'\n",
    "train_fname = \"biencoder_monitor.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(embeddings_folder,\"rb\") as f:\n",
    "    entity_emebeddings=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29ef4a85050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_process import *\n",
    "def process_mention_data_2(samples,tokenizer):\n",
    "    \n",
    "    max_context_length=64\n",
    "    mention_key=\"mention\"\n",
    "    context_key=\"context\"\n",
    "    ent_start_token=\"[unused0]\"\n",
    "    ent_end_token=\"[unused1]\"\n",
    "    \n",
    "    processed_samples = []\n",
    "    all_samples = []\n",
    "    iter_ = samples\n",
    "\n",
    "    for idx, sample in enumerate(iter_):\n",
    "        context_tokens = get_context_representation(sample,tokenizer,max_context_length,mention_key,context_key,ent_start_token,ent_end_token)\n",
    "                        \n",
    "        record = {\"context\": context_tokens}\n",
    "            \n",
    "        processed_samples.append(record)\n",
    "        all_samples.append(sample)\n",
    "        \n",
    "    context_vecs = torch.tensor(\n",
    "        select_field(processed_samples, \"context\", \"ids\"), dtype=torch.long,\n",
    "    )\n",
    "    data = {\n",
    "        \"context_vecs\": context_vecs,\n",
    "        \"sample\":all_samples\n",
    "    }\n",
    "\n",
    "    tensor_data = TensorDataset(context_vecs)\n",
    "    return data, tensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aydxng\\Anaconda3\\envs\\Python37\\lib\\site-packages\\urllib3\\connectionpool.py:988: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "C:\\Users\\aydxng\\Anaconda3\\envs\\Python37\\lib\\site-packages\\urllib3\\connectionpool.py:988: InsecureRequestWarning: Unverified HTTPS request is being made to host 'huggingface.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctxt_model = torch.load(model_path).to(device)\n",
    "m = torch.load(model_path_m).to('cpu')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "ctxt_model.eval()\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4635\n"
     ]
    }
   ],
   "source": [
    "# Load train data \n",
    "train_samples = []\n",
    "with open(train_fname, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        train_samples.append(json.loads(line.strip()))\n",
    "print(len(train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_entities = [x['label_id'] for x in train_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_tensor_data = process_mention_data_2(train_samples,tokenizer)\n",
    "\n",
    "train_sampler = SequentialSampler(train_tensor_data)\n",
    "train_dataloader = DataLoader(train_tensor_data, sampler=train_sampler, batch_size=input_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Step:  0   0.0020003318786621094\n",
      "Step:  10   26.73799729347229\n"
     ]
    }
   ],
   "source": [
    "ctxt_model.eval()\n",
    "print(len(train_dataloader))\n",
    "mention_embeddings = []\n",
    "with torch.no_grad():\n",
    "    start = time.time()\n",
    "    for step, context_input in enumerate(train_dataloader):\n",
    "        if step%10==0:\n",
    "            print(\"Step: \",step,\" \",time.time()-start)\n",
    "        context_input = context_input[0]\n",
    "        this_batch= context_input.size(0)\n",
    "        ctxt_rep = ctxt_model(context_input.to(device))[0][:,0,:]\n",
    "        for i in range(this_batch):\n",
    "            mention_embeddings.append(ctxt_rep[i].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4635\n",
      "4635\n"
     ]
    }
   ],
   "source": [
    "print(len(mention_embeddings))\n",
    "print(len(correct_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0239, -0.0422, -0.0118,  ..., -0.0118, -0.0314,  0.0001],\n",
       "         [ 0.0168,  0.0165,  0.0089,  ...,  0.0202,  0.0258, -0.0039]],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Param for positive class\n",
    "m_second_param = list(m.parameters())[0][1].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hard_negs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   0.0\n",
      "100   32.84685015678406\n",
      "200   66.40477561950684\n",
      "300   97.43366742134094\n",
      "400   128.82752132415771\n",
      "500   159.65541577339172\n",
      "600   188.50035548210144\n",
      "700   217.80125546455383\n",
      "800   248.62711668014526\n",
      "900   277.9820554256439\n",
      "1000   309.2220368385315\n",
      "1100   337.14903140068054\n",
      "1200   368.3189971446991\n",
      "1300   400.0930256843567\n",
      "1400   431.1390235424042\n",
      "1500   461.37198424339294\n",
      "1600   490.5609850883484\n",
      "1700   519.8990159034729\n",
      "1800   550.4800109863281\n",
      "1900   579.5689742565155\n",
      "2000   609.9169683456421\n",
      "2100   640.2099559307098\n",
      "2200   670.5229458808899\n",
      "2300   700.9999725818634\n",
      "2400   730.4999628067017\n",
      "2500   760.7699189186096\n",
      "2600   790.6549112796783\n",
      "2700   823.4849364757538\n",
      "2800   852.9449265003204\n",
      "2900   884.6279172897339\n",
      "3000   914.2908797264099\n",
      "3100   945.3879113197327\n",
      "3200   976.0189082622528\n",
      "3300   1006.4498980045319\n",
      "3400   1036.5666904449463\n",
      "3500   1066.5614838600159\n",
      "3600   1095.912284374237\n",
      "3700   1125.6070432662964\n",
      "3800   1154.815840959549\n",
      "3900   1184.3646712303162\n",
      "4000   1214.213428735733\n",
      "4100   1246.4082436561584\n",
      "4200   1275.0060472488403\n",
      "4300   1305.469829082489\n",
      "4400   1334.5698261260986\n",
      "4500   1364.2888214588165\n",
      "4600   1394.492811203003\n"
     ]
    }
   ],
   "source": [
    "hard_negatives = []\n",
    "predictions = []\n",
    "score_predictions = []\n",
    "corr_entity_scores = []\n",
    "start = time.time()\n",
    "for i in range(len(mention_embeddings)):\n",
    "    if i%100 == 0:\n",
    "        print(i, \" \",time.time()-start)\n",
    "    this_ment_embed = mention_embeddings[i]\n",
    "    this_corr_ent = correct_entities[i]\n",
    "    #For NIL mentions this score is set to 0 for the negative mining strategy\n",
    "    score_corr_ent = 0.\n",
    "    if this_corr_ent is not None:\n",
    "        this_corr_ent = int(this_corr_ent)\n",
    "        score_corr_ent =  1/(1 + np.exp(-np.sum(np.multiply(np.multiply(this_ment_embed,entity_emebeddings[this_corr_ent]),m_second_param))))\n",
    "    #print(\"Correct Entity: \",this_corr_ent,\" score: \",score_corr_ent)\n",
    "    \n",
    "    link = None\n",
    "    score_link = 0\n",
    "    this_hard_negatives = None\n",
    "    \n",
    "    for k,v in entity_emebeddings.items():\n",
    "        score_this =  1/(1 + np.exp(-np.sum(np.multiply(np.multiply(this_ment_embed,v),m_second_param))))\n",
    "        if score_this>score_link:\n",
    "            score_link = score_this\n",
    "            link = k\n",
    "        if k!=this_corr_ent:\n",
    "            if score_this >= score_corr_ent:\n",
    "                if this_hard_negatives is None:\n",
    "                    this_hard_negatives = PriorityQueue(num_hard_negs)\n",
    "                if this_hard_negatives.full():\n",
    "                    temp = this_hard_negatives.get()\n",
    "                this_hard_negatives.put((score_this,k),False)\n",
    "    \n",
    "    corr_entity_scores.append(score_corr_ent)\n",
    "    hard_negatives.append(this_hard_negatives)\n",
    "    predictions.append(link)\n",
    "    score_predictions.append(score_link)\n",
    "    #print(\"Prediction: \",link,\" score: \",score_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_negatives_new = []\n",
    "for item in hard_negatives:\n",
    "    if item is None:\n",
    "        hard_negatives_new.append(None)\n",
    "    else:\n",
    "        hard_negatives_new.append(item.queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4635\n",
      "4635\n",
      "4635\n",
      "4635\n",
      "4635\n",
      "4635\n"
     ]
    }
   ],
   "source": [
    "print(len(train_samples))\n",
    "print(len(correct_entities))\n",
    "print(len(corr_entity_scores))\n",
    "print(len(hard_negatives_new))\n",
    "print(len(predictions))\n",
    "print(len(score_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hard_negatives_monitor_round_2.pkl\",\"wb\") as f:\n",
    "    pickle.dump(hard_negatives_new,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "num_all = 0\n",
    "for i in range(len(train_samples)):\n",
    "    if correct_entities[i] is not None:\n",
    "        num_all +=1\n",
    "        if hard_negatives_new[i] is None:\n",
    "            num_correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3237"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3967"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8159818502646836"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct/num_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision:  0.6997\n",
      "Micro Recall:  0.8175\n",
      "Micro F1 Score:  0.754\n",
      "Both not NIL and same:  3243\n",
      "Both not NIL and different:  724\n",
      "Correct is NIL, linked is not NIL:  668\n",
      "Correct is not NIL, linked is NIL:  0\n",
      "Both are NIL:  0\n"
     ]
    }
   ],
   "source": [
    "PRF_debug(correct_entities, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.66\n",
    "thresholded_predictions = []\n",
    "for i in range(len(train_samples)):\n",
    "    if score_predictions[i] >=threshold:\n",
    "        thresholded_predictions.append(predictions[i])\n",
    "    else:\n",
    "        thresholded_predictions.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro Precision:  0.8066\n",
      "Micro Recall:  0.7862\n",
      "Micro F1 Score:  0.7963\n",
      "Both not NIL and same:  3119\n",
      "Both not NIL and different:  529\n",
      "Correct is NIL, linked is not NIL:  219\n",
      "Correct is not NIL, linked is NIL:  319\n",
      "Both are NIL:  449\n"
     ]
    }
   ],
   "source": [
    "PRF_debug(correct_entities, thresholded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRF_debug(correct, linked, print_err = False):\n",
    "    #Same function, also outputs the individual numbers\n",
    "    #Case 1: Both not NIL and same -> tp             \n",
    "    #Case 2: Both not NIL and different -> fp and fn\n",
    "    #Case 3: Correct is NIL, linked is not NIL -> fp\n",
    "    #Case 4: Correct is not NIL, linked is NIL ->fn\n",
    "    #Case 5: Both are NIL -> nothing                \n",
    "    \n",
    "    #Stores: micro precision, micro recall, micro f1 score,\n",
    "    #macro precision, macro recall, macro f1 score\n",
    "    metrics = []\n",
    "    \n",
    "    tp = []\n",
    "    fp = []\n",
    "    fn = []\n",
    "    \n",
    "    case1 = 0\n",
    "    case2 = 0\n",
    "    case3 = 0\n",
    "    case4 = 0\n",
    "    case5 = 0\n",
    "    \n",
    "    for i in range(len(correct)):\n",
    "        correct_entity = correct[i]\n",
    "        linked_entity = linked[i]\n",
    "        \n",
    "        if correct_entity is not None and linked_entity is not None:\n",
    "            #When read from csv some entity ids were converted to float for some reason\n",
    "            linked_entity = str(int(linked_entity))\n",
    "            #Catch cases where there is something wrong with correct entity id\n",
    "            try:\n",
    "                correct_entity = str(int(correct_entity))\n",
    "            except ValueError as e:\n",
    "                if print_err:\n",
    "                    print('Error str: ',e)\n",
    "                    print('Index: ',i)\n",
    "                tp.append(0)\n",
    "                fp.append(0)\n",
    "                fn.append(0)\n",
    "                continue\n",
    "                \n",
    "            #Case 1\n",
    "            if str(int(correct[i])) == str(int(linked[i])):\n",
    "                tp.append(1)\n",
    "                fp.append(0)\n",
    "                fn.append(0)\n",
    "                case1 += 1\n",
    "            #Case2\n",
    "            else:\n",
    "                tp.append(0)\n",
    "                fp.append(1)\n",
    "                fn.append(1)\n",
    "                case2 += 1\n",
    "        \n",
    "        #Case 3\n",
    "        elif correct_entity is None and linked_entity is not None:\n",
    "            tp.append(0)\n",
    "            fp.append(1)\n",
    "            fn.append(0)\n",
    "            case3 += 1\n",
    "        \n",
    "        #Case 4\n",
    "        elif correct_entity is not None and linked_entity is None:\n",
    "            tp.append(0)\n",
    "            fp.append(0)\n",
    "            fn.append(1)\n",
    "            case4 += 1\n",
    "        \n",
    "        #Case 5\n",
    "        else:\n",
    "            tp.append(0)\n",
    "            fp.append(0)\n",
    "            fn.append(0)\n",
    "            case5 += 1\n",
    "            \n",
    "    micro_precision = np.round(np.sum(tp)/(np.sum(tp)+np.sum(fp)+(10**-6)),4)\n",
    "    micro_recall = np.round(np.sum(tp)/(np.sum(tp)+np.sum(fn)+(10**-6)),4)\n",
    "    micro_f1 = (2*micro_precision*micro_recall)/(micro_precision+micro_recall+(10**-6))\n",
    "        \n",
    "    print('Micro Precision: ', np.round(micro_precision,4))\n",
    "    print('Micro Recall: ', np.round(micro_recall,4))\n",
    "    print('Micro F1 Score: ', np.round(micro_f1,4))\n",
    "    \n",
    "    \n",
    "    print('Both not NIL and same: ', case1)           \n",
    "    print('Both not NIL and different: ', case2)\n",
    "    print('Correct is NIL, linked is not NIL: ', case3)\n",
    "    print('Correct is not NIL, linked is NIL: ', case4)\n",
    "    print('Both are NIL: ', case5)              \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.ones([10, 64], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "output = torch.full([10, 64], 1.5)  # A prediction (logit)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
